### Vo_1: Untersuchungsformen






### Vo_2: Versuchsdesigns
### Vo_3: Datenerfassung
### Vo_4: Kausalität
### Vo_5: Quasiexperiment
### Kausalität-Validität
### Vo_6: Zeitreihendesigns
### Vo_7: Fallzahlenplanung
### Vo_8: Stichproben
### Vo_9






### Mathstuff
### Fragen-derArt(short)
### Fragen-Der-Art(long)


# Vo_1: Untersuchungsformen

### 1. Warum bedürfen auch publizierte Forschungsergebnisse einer gewissen Skepsis?
```
- Vorauswahl der zu publizierenden Forschungsergebnisse
- Publikationsdruck
- massive Nicht-Veröffentlichung
- mythisierung der Ergebnisse
- Replikationen für Forscher sind unattraktiv

(Gerade in Psychologie sind aber auch implizites Wissen, Überblick und Erfahrung wichtig, nicht nur die Kenntnis konkreter Studienergebnisse)

- Autir*innengruppen mit immer denselben Ergebnissen (mobilfunk, homöopathie)
- In Auftrag gegebene STudie von xxx kommt zu dem ergebniss das...xxx
- Competing interest statement! -> keine finanziellen interessen an ergebnissen der STudie

- "kritisches Denken" - aber wem gegenüber sollten wir kritisch sein, wem sollten wir vertrauen?

- schulmäßige interpretation von experimentellen ergebnissen -> "man" interpretiert ergebniss so und nicht anders -> spiegel verhindert schummeln

- wissenschaftlicher supergau: post hoc-Deutungen("männer reden weniger weil immer noch Jäger")

-> "Richtige" Wissenschaft:
- arbeitet sachlich und emotionsfrei
- schlussfolgert frei von Hintergedanken und persönlichen Befindlichkeiten
- ist nicht autoritäthörig
-  argumentiert zur Sache, nicht zur Person
- ist ergebnisoffen
- überprpft ihre Annahmen und Quellen
- argumentiert präzise und quantifiziert (wenn möglich)
- versucht ihre Modelle an die Wirklichkeit anzupassen
- versucht Vorhersagen zu erstellen, welche sich potentiell falsifizieren lassen, und reagiert auf Falsifikation in angemessener Weise
- hinterfrag sich selbst und überprüft ihre Schlussfolgerungen (wenn mäglich empirisch)
- liefert schlüssige Begründungen, zieht aber auch alternative Deutungsmöglichkeiten in Betracht
- schlussfolgert systematisch und vollständig (im Gegensatz zu selektiv) und konsequent
- Wägt ab anstatt Dinge zu ignorieren/auszublenden
- hält keine informationen zurück
- ist vorischtig mit kausalinterpretationen
- weiß um ihre grenzen und verheimlicht sie nicht
```

[back](bla)



### 2. Verschiedene Ausrichtungen wissenschaftlicher Untersuchungen mit eigenem Beispiel. (Gemeint ist: explorativ, beschreibend, hypothesenprüfend) "Eigen" heißt dabei: von Ihnen selbst gefunden.

Explorative Untersuchung:

-> sondierend, aufklärend, erforschend, hypothesengenerierend

-> Beispiel:

Populationsbeschreibende Untersuchungen:

-> hinsichtlich ausgewählter Merkmale

-> Beispiel:

Hypothesenprüfende Untersuchungen:

-> Beispiel


### 3. Mögliche Strategien der Themenfindung zu einer wissenschaftlichen Untersuchung.

- "neue" Idee oder Replikation/Meta-Analyse?
- Fallstudien
- Introspektion
- Auffällige/paradoxe Phänomene/Wiedersprüche
- Alltagsphänomene
- Problemverhalten


### 4. Nach welchen Kriterien lassen sich Untersuchungsideen bewerten (mit kurzer Erläuterung)?

```
- Präzision der Formulierung

- Empirische Untersuchbarkeit
(nature-nurture-Problematik, Wirksamkeit, können wir ein problem überhaupt untersuchen)

- Relevanz: Für die Wissenschaft- für die Gesellschaft

- Ethische Erwägungen; Werteabwägungen Erkenntnisnutzen vs Belastung;Freiwilligkeit;Anonymität;Ethikkomitees
````

### 5. Was ist bei der Planung einer Unterschung festzulegen?

```
- Literaturrecherche: Überblick über Stand der Forschung, Vertiefung

- Wahl der Forschungsmethode entsprechend der Fragestellung/Zielsetzung

- Definitonen und Operationalisierungen: was bedeuten meine Begriffe, und wie genau sollen sie möglichst gut erhoben werden; Messung und Skalierung

Auswahl an Stimuli, Stichprobenauswahl bzw. -rekrutierung(inkl. Fallzahlplanung)
```

### 6. Explorative Untersuchung. Erläutern Sie verschiedene Typen von Explorationen(theoriebasiert etc.)

```
- Theoriebasierte Exploration: Systematische Durchsicht und Analyse aus vorhandenen wissenschagtlichen und alltäglichen Theorien -> Ableitung neuer Hypothesen

- Methodenbasierte Exploration: Vergleich und Variation von Methoden, welche Methoden wurden noch nicht verwendet, welche Ergebnisse kommen nur in Kombination mit welchen Methoden vor?

- Empirisch-quantitative Exploration: Besondere Darstellung auf Aufbereitung von quantitativen Daten; Sichtbarmachung unberücksichtigter Muster und Regeln
-> suche nach quantitative Muster

- Empirisch-qualitative Exploration: Besondere Darstellung auf Aufbereitung von qualitativer Daten; Sichtbarmachung unberückstichtikter Muster Verläufe, Phänomene
-> qualitativ meist mit  explorativ assozieriert
```

### 7. Fragen der Art: Eine Untersuchung soll klären, welche Einkommensverhältnisse (Einkommen bzw. staatliche/private Zuwendung) alleinerziehende Eltern charakterisieren. Um welche Art von Exploration handelt es sich dabei?

-> Beispiele für Untersuchungen

### 8. Arten von explorativer Datenerhebungen (gemeint ist die Liste von offener Beobachtung bis Aktionsforschung)(mit kurzen Erläuterungen.)

- Einzelfallanalyse:

in Selbstbeobachtung oder Fremdbeobachtung -> Vorbereitung auf Stichprobenuntersuchungen

- Non-reaktive Verfahren:

bspw. big data (chats) erfassung-> Datenerhebungsmethoden die keinerlei Einfluss auf ie untersuchten Personen, Ereignisse oder Prozesse haben. Kein Kontakt zw. Beobachter unt untersuchter Person

- Inhaltsanalysen:  

Zentrale Themen und/oder Bedeutung von Texten oder anderen Objekten (Bilder, Fotos, Kunstobjekte etc.) werden herausgearbeitet

- Aktionsforschung:

Wissenschaftler*innen definieren zusammen mit Betroffenen die Problemstellung, such nach den Ursachen und entwerfen Lösungsvorschlge(Interventionen)
der Erfolg der Interventionen wird dann gemeinsam bewertet(evaluiert) und führt zur modifikation...


### 9. Fragen der Art: Geben Sie ein eigenes Beispiel für Feldbeobachtung.

Beispiele:

### 10. Fragen der Art: Um die Lebensqualität in PFlegeheimen zu untersuchen, verbringt ein Forschungsteam einen Monat in einer entsprechenden Einrichtung. Um welche Art von Studie handelt es sich dabei (mit Begründung)?

Beispiel:

### 11. Poulationsbeschreibende Untersuchungen.

- Beschreibung von Population hinsichtlich ausgewählter Merkmale. Zentrales Thema dabei ist die Stichprobenerhebung und Schätzung der unbekannten Poplationsparameter.

### 12. Hypothesenprüfende Untersuchungen.

explanativ -> Formulierung von Hypothesen aufgrund des Standes der Theorienentwichlung bzw. aufgrund von explorativen Untersuchungen

- Zusammenhangshypothese (Korrelation)

- Unterschiedshypothesen (t-test, anova...)

- Veränderungshypothesen (repeated measure anova, abhängiger t test)

- Einzelfallhypothesen (zeitreihen)

- Unspezifische vs. spezifische Hypothesen: Unspetzufische Hypothesen gehen von einem irgenwie geartetetn Effekt aus, allenfalls Richtung angegeben, spezifische hypothesen geben auf den betrag des effekts bzw die effektgröße an.

### 13. Definition und Eigenschaften des Experiments.

-> Das Experiment ist eine:  

```   
- geplante, systematische Beobachtung
- untersucht Effekte von unabhängigen auf abhängige Variblen
- Resultate sind Replizierbar
-> erlaubt kausalschluss.

- !experimentelle Bedingungen müssen vom VersuchsleiterIn willkürlich hergestellt und systematisch variiert werden (min Versuchs und Kontrollgruppe);
- !alles anderen Bedingungen müssen konstant gehalten werden

- Untersuchungsobjekte werden per Zufall in Gruppen Eingeteilt, Randomisierung
```

### 14. Randomisierung. Welchen Effekt hat sie genau?

###### -> Randomisierung:
```  
- ist eine Zufällige Zuteilung von Personen zu experimentellen Bedingungen (zB Versuchs/Kontrollgruppe)

- durch Randomisierung werden Systematische personenbezogene Störvariablen ausgeschaltet

- zufällige Unterschiede zwischen VGs aber möglich (deshalb Signifikanztest)

- Randomisierung != Parallelisierung

- durch Konstanthalten nicht experimenteller Bedingungen sowie Randomisierung sind im strengen Experiment theoretisch Kausalschlüsse der Form A verursacht B möglich, weil alle Störeinflüsse kontrolliert werden können.
```  


### 15. Quasi-experimentelle Untersuchung. Wodurch genau unterscheiden sie sich von Experimenten/nicht-experimentellen Studien?

###### -> Quasiexperimentele Untersuchungen
```  
-> keine randomisierung möglich!

-> arbeiten mit natürlichen (vordefinierten) Gruppen.

-> Sie unterscheiden sich dadurch vom Experiment das verlangen würde durch Randomisierung
systematische personenbezogene Störeinflüsse ausszuschließen
```

### 16. Fragen der Art: Entwerfen Sie in wenigen Stichworten ein Quasi-Experiment, um den Effekt eines Programms zu testen, welches Schülerinnen einer AHS zu einem naturwissenschaftlichen Studium motivieren soll. was sind die schwächen dieses Designs? wie kann man sie minimieren?

```  
- 2 klassen werden verglichen. eine klasse bekommt programm das zu naturwissenschaftlichem studium motivieren soll, die zweite schaut einen film. anschließende befragung welche studien interesse wecken.

Schwächen:
- keine randomisierung möglich der schüler die dem programm zugewiesen werden möglich.
- wenn das programm freiwillig angeboten wird, kann allein das interesse an naturwissenschaften generell dazu führen das sich schüler die am programm teilnehmen mehr motiviert erscheinen ein naturwisschenschafltiches studium zu wählen.
- langzeiteffekte können hier nicht ermittelt werden, es ist nicht klar ob schüler später ein nat st wählen, und selbst wenn ja dann ist nciht klar ob wegen dem programm.
- minimieren durch Parallelisierung der Leistung -> ergibt problem das leistung nicht zwangsläufig mit interesse/motivation korreliert
```  

### 17. Parallelisierung und deren Eigenschaften

- wichtige prä-experimentelle Unterschiede die sich auf die abhöngige varaiablen auswirken könnten zu werden bei der Gruppeneinteilung Berücksichtigt

- zB Alter geschlecht bildungsstand

- Parallelisierung erhöht die interne Validität von quasiexperimentellen Untersuchungen



### 18. Interne und externe Validität, Zusammenhang mit Feld- bzw- Laborstudien.

- Interne Validität:
```  
Veränderungen in der abhängigen Variable sind eindeutig auf Einfluss der Unabhängigen zurückzuführen, es gibt also keine Alternativerklärungen der Untersuchungshypothese
```

- Externe Validität:
```  
Die in einer Stichprobenuntersuchung gefunenen Ergebnisse können auf andere Personen, Situationen oder Zeitpunkte generalisiert werden
```  

|  | Experimentell | Quasiexperimentell |
| ------------- | ---------------------- | ------------------------ |
| `Feldstudie` | Interne Validität (hoch) | Interne Validiät (Niedrig) |
|  | Externe Validität (hoch) | Externe Validiät (hoch) |
| `Labor` | Interne Validität (hoch) | Interne Validiät (Niedrig) |
|  | Externe Validität (niedrig) | Externe Validiät (Niedrig) |


### 19. Fragen der Art: Sie testen den Effekt von Mobiltelefonen auf die Gesundheit, indem Sie VielbenutzerInnen mit Wenig-BenutzerInnen vergleichen. Um welches Versichsdesign handelt es ich?

Feldstudie Quasiexperimentell

### 20. Fragen der Art: Skizzieren Sie ein experimentelles/ein nicht-experimentelles Versuchsdesign für eine Studie, welche den Effekt drastischer Fotos auf Zigarettenpackungen erfassen soll.

Experiment:

```
Zufallszuordnung zu zwei Gruppen, eine hat verhalten A andere B
anschließende einstufung ob verhaltensänderung wahrscheinlich
vergleich Ratings
Problem:
- artifizielle Situation,
- Ausagekrangt der Selbsteinstufung
- wird wirklich eine Verhaltensänderung erfolgen?
```

Feldstudie:

```
wechseln der Kampange nach einem Jahr, vergleichen ob die entsprechen Kennzahlen sich ändern
Problem: selbst wenn die Kennzahlen sich verändern, bleibt unklar ob durch Kampagne oder allgemeine erignisse (wirtschaft, krise)
```

### 21. Kann es "Gender-Experimente" geben?

```  
- Genderexperimente sind umöglich hinsichtlich randomisierter einteilung des Geschlechts der teilnehmenden Personen

- jedoch möglich hinsichtlich Geschlecht als Stimulusbedingung, Bspw. Author eines Artikels männlich/weiblich, vergleich der probandenreaktionen.
```  

### 22. Doppelblind, double-dummy, RCT, baslineComparison, manipulationCheck

- Doppelblind:
```
weder Versuchsleiter*in noch Teilehner*in wissen über Zugehörigkeit zu Versuchsbedingungen bescheid.
-> noch besser dreifachblind, auch ausertende Person weiß nicht welche Gruppe Versuchsgruppe ist.
```  

- double-dummy:
```  
nicht behandlung maskiert als behandlung (zB injektion mit placebo)
```  

- RCT
```
Randomized Controlled trial
-> für medizinische Effektkontrollstudien
-> prospektiv ergo voher geplant
-> theoretischer goldstandard, perfektes Experiment
-> Randomisierung oft ethisch problematisch (nicht behandlung der kontrollgruppe)
-> need for ethikkommitee
```  

- Baseline comparison
```
zwischen experimentellen Gruppen ( um präexoerimentelle Gruooen zu kontrollieren bzw. um die Randomisierung zu prüfen, oft viel problematischer als im protokoll ersichtlich)
```  

- manipulationCheck
```
bspw. prüfung ob aktivierende Bedingung wirklich aktiviert
bzw ob cover story wirklich funktioniert,
auch ob probanden gesichter die sie sich merken sollten wirklich sich gemerkt haben.
```

### 23. Fragen der Art: Was bedeuten die im Kapitel klinische Standards RCTs etc. erwähnten Begriffe konkret wenn sie den Effekt von Akupunktur mittels einer klinischen Studie nachweisen wollen?

- Doppelblind:
```
Coverstory!
Testleiter lernen zwei arten von Akupunktur Applikation, eine die nach standard Akupunktur Richtlinien wirkt, eine bei der an anderen stellen in die haut gestochen wird.
jeh nach Bedingung wenden die testleiter dann eines der beiden verfahren an.
zusätzlich Vorselektion, damit keine probanden eingeladen werden die wissen im bereich Akupunktur mit bringen.
```  

- double dummy:
```
wie oben erwänt, bedingung A sticht da ein wo Akupunkturbehandlung effekt vermutet, bedungung B muss auch einstechen, jedoch an stellen die mit standard Akkupuntur behandlung nicht im zusammenhang stehen.
```

- RCT
```
effekte werden voher geplant,
klare hypothesen bei welcher behandlung akupunktur wirkt.
probanden werden zufällig (randomisiert) zu versuchsbedungungen (akku, palcebo) zugeteilt.
```

- Baseline comparison


- manipulation check.
```
glauben sie das die Behandlung etwas gebracht hat.  
```


### 24. Pre protocol, as treated, intention to treat. Was ist die Idee hinter intention to treat?

- per-protocol-analyse:

```  
nur jene patientInnen dabei, welche sich konform verhalten haben, nur "korrekte Fälle"
```  

- As treated:

```
patientInnen so zugeordnet, wie sie tatsächlich behandelt wurden, (auch wenn Behandlung ursprünglich anders geplant war) - kann also alle patientInnen einbeziehen.
```  

!problem bei beiden, bias, selektive Auswahl zu befürchten, zB schwererere Fälle wechseln zu Versuchsgruppe

- intention-to-treat:

```  
PatientInnnen nach ursprünglicher Zuordnung zu Behandlung ausgewertet => ignoriere Abweichungen vom Plan bewusst, um die Randomisierung nicht aufzuweichen.

- intention to treat behält randomisierungscharacter der daten bei.
- wenn es unterschiede gibt sind sie nur durch randomisierte bedingung zu erklären  
- daten sind dann natürlich verunreinigt, aber nicht systematisch verzerrt.
```  

### 25. Ordnen Sie die Begriffe per protocol, as treated und intention to treat richtig zu:

- Fragen der Art:  

```
in einer klinischen Studie gibt es ungeplante Wechsel von der Kontroll- zur Versuchsgruppe, weil einige Fälle der Kontrollgruppe nicht unbehandelt bleiben sollen. Die statistische Auswertung kann nun erfolgen, indem jede Person der ursprünglich für sie vorgesehenen Gruppe zugordnet wird: intention-to-treat, oder indem die wechselnden Personen aus der Auswertung gestrichen werden: "per-protocol", oder indem jede Person der Behandlung zugeordnet wird, welche sie tatsächlich erhalten hat: as-treated
```

### 26. Evidenzpyramide. Welche Studien liefern "höherwertige Evidenzen?"

```  
- (Metaanalyse)
- RCT-DB
- RCTs
- Kohortenstudie (längsschnittstudie, eine kohorte über zeit)
- Fall-Kontroll-STudie (retrospektiv, erkrankte und nicht erkrantke werden verglichen auf ursachen)
- Fallserie
- Fallbericht
- Expertenmeiung
- Forschungsstudien an Tieren.
- in-vitro.Studien (außerhalb eines lebenden organismus)
```  


# Vo.3 Datenerfassung

### 27. Verschiedene qualitative Zugänge zur Datenerhebung ( mit kurzer erläuterung). (Gronded Theory, Thematische Analyse, )

- Grounded Theory:

```  
für vorurteilsfreies entwickeln einer theorie

-> Glase & Strauss 1967
-> Theorieentwichlung/modifikation auf Basis qualitativer Datenerhebung
-> Vorurtelsfreies, offenes Herangehen ans Material

ua:
.permanenter Vergleich, ständiges Zurückgehen in die Daten, um Arbeitshypothesen zu validieren bzw. weiterzuentwickeln

.Memos: aufschreiben der beim durcharbeiten enstehenden Gedangken
```  

- Thematische Analyse (Braun):
bottomUp

| Phase | Description of the process |
|-------|----------------------------|
|1. Familiarising yourself with your data|Transribing data, reading, rereading, noting down inital ideas|
|2. Generating initial code:| Coding interesting features of the data in a systematic fashion across the enteire data set. collating data relevant to each code|
|3.Searching for themes|Collating codes into potentioal themes, gathering all data relevant to each potential theme.|
|4. Reviewsing themes|Checking in the themes work in relation to the coded extracts(lvl1) and the entire data set lvl2, generating a thematic map of the analysis|
|5. Defining and naming themes:|Ongoing analysis to refine the specifics of each theme, and the overall story the analysis tells; generating clear definitons and names for each theme|
|6. prducing the report|the final opportunity for analysis, selection of vivid, cimpelling extract examples, final analysis of selected extract, relating back of the analysis to the research question and literature producing scholarly report of the analysis|

- thematic map(holovics, 2015)
dinge die man sieht möglichst strukturiert zu papier bringen

- Qualitative Inhaltsanalyse nach Mayring:
???



### 28. Operationalisierung, Messung, Skala`

- Operationalisierung:
```  
Vorschrift wie ein theoretisches Konstrukt konkret durch angabe der Messoperationen messbar gemacht werden soll.

auch, wie messbare erignisse das vorliegen anzeigen sollten
```  

- Messung:
```  
die zuordung von zahlen zu objeten oder Ereignisstichproben
sofern diese zuordnung empirische beziehungen strukturtreu in zahlen abbildet
anders als pyhsik messungungen, kein urmeter für psychologische messungen oftmals gegeben.
```  

- Skala:
```
verknüpfung zwischen empirischen und numerischen bezihungen.
```  

### 29. Methoden der Datenerfassung

```  
1. Mündliche Befragung per Interview oder Gruppendiskussion
2. Inhaltsanalyse
3. Beobachtung
4. Schriftliche Befragung per Fragebogen
5. Einholen einer Beurteilung/Bewertung
6. Vorgabe von Tests.
7. Experiment
```  

### 30. Kriterien um Interviews charaktersieren. Welche Möglichkeiten gibt es für Gruppen?

```  
- 1. Ausmaß der Standardisierung (strukturiert(abvolge der fragen eindeutig, antworten auch), halb , unsturkturiert(nichtstandardisiert-> nur theoretischer ramen, für explorative studien, persönlichkeit interviewer entscheidend))
- 2. Autoritätsanspruch der intervieweden Person (weich,neutral hart)
- 3. Art des Kontakts (telefon, schriftlich)
- 4. Anzahl der befraten perosnen (einzel, vs gruppeninterview)
```

- für Gruppen:

```
- Gruppenbefragung:
Zumeist mit natürlcihen Gruppen, mögliche konkrenzsituatiinen
- Gruppendiskusionen:
aktive Gesprächsbereitschaft aller Teilnehmerinnen
interviewerinnen geift nur gelegentlcih ein
möglichst homogene gruppen benötigt
(Gruppeninterview, gruppendiskusion, fokusgruppe(interaktion, zurück zum thema))
- Board Interview/ hearing
mehrere Intervierinnen
auswahlsituiationen
belastend für repsndenitnnen
```  

### 31. Worauf bei der mündlichen Befragung zu achten Liste

```  
- Suggestivfragen vermeiden, aber empathisch nachfragen

- Kontexteffekt _> Antworten hängen vom kontext ab indem gefagt wird

- priming effekt -> beantworung einer vorgängerfrage wirt sich auf beantworung der nachfolgenden frage aus

- Transkription -> ton und vid aufzeichnungen sollten verschriftlicht werden, non verbale transkriptionszeichen
```  

### 32. Systematische Beobachtung, und was dabei festzulegen ist.

- eine beobachtung kann nicht realitätsgetreue abbildung des zu beobachtenden sein, da bestimte Entscheidungen getroffen, dinge ins zentrum der aufmerksamkeit gerückt werden müssen
- Alltagsbeobachtungen: finden nach individuellen interessen und werten statistische

-> Systematische Beobachtung:

```  
-setzt demgegenüber einen Beobachtungsplan voraus:

-> Was wird von wem beobachtet?
-> Was ist wesentlich, was ist unwesentlich?
-> Darf gedeutet werden und wenn ja, wie?
-> Wann und wo wird beobachtet?
-> Wie wird protokoliert?
```

### 33. Schritte bei einer Beobachtung (Selektion, Abstraktion etc.)

```  
- Selektion: Auswahl bestimmter Beobachtungsgegenstände.

- Abstraktion: Ereignis wird aus seinem konkreten Umfeld herausgelöst
und auf wesentliche Bedeutung reduziert. bsp ich will zorn beobachten, was ist dass

- Klassifikation: Zuordung von Zeichen und Symbolen zu bestimmten Ereignis oder Merkmalsklassen.
  in welche kategirie fällt das verhalten
- Systematisierung: Zeichen und Beobachtungen werden mit zahlen Kodiert  und zu übersichtlichem gesamtprotokoll zusammengestellt.

- relativierung: Ausagegehalt des Untersuchgmaterials muss auf breieren theoretischen Rahmen bezogen werden.
```  

### 34. Arten von Beobachtungen in Bezug auf die Rolle der beobachtenden Person (mit kurzer erklärung) (teilnehmend verdeckt etc.)

```
(offen: rolle des beobachters ist klar)

- Teilnehmende offene Beobachtung:
  ->Sozialarbeiter verbringt einen Tag mit klient

- Teilnehmende verdeckte Beobachtung:
  -> Als Kunde im einkaufsladen, um freundlichkeit der verkäufer gegenüber kunden zu beobachten.

- Nicht-teilnehmende offene Beobachtung:
  -> Psychologe sitzt im altersheim und protokoliert verhalten von kunden und pflegern.


- Nicht- teilnehmende verdeckte Beobachtung: Video des Verhaltens von studenten wärend der vorlesung wird auf konzentration untersucht.

```

### 35. Zeit und Ereignisstichproben (Beobachtungen)

-> generellesProblem: Beobachung kann immer nur einen Ausschnitt des Geschehens erfassen:


- Ereignisstichprobe:

```  
Beobachtete Ereignisse werden nicht zeitlich strikuriert protokolliert, es kommt nur darauf an festzustellen, wie oft ein erignis auftritt und welche erigniskombinationen vorkommen
```  

- Zeitstichprobe:

```   
Beobachtung wird in feste Zeitabschnitte gegeliedert
-> ProbleM: Sindt bestimmte Phasen eine Verhaltenssquenz wichtig und sicnd diese nicht im zeitfenster gehen sie verloren

entscheidung für Zeit oder erignisstichpobe ist kontextabhängig
```  

### 36. Cohens´s Kappa, evtl. mit Erklärung der grundlegenden Idee anhand eines eignen Beispiels.

Cohens Kappa:
```
-> Maß zur Beurteilung der Beobachterübereinstimmung
-> Relativiert die Anzahl der Übereinstimmungen an erwartette Anzahl an übereinstimmungen

Für 2 Rater, bzw. der selbe an mehreren Zeitpunkten:

kohens kappa, soll uns die interraterreabilität angeben. also den grad der übereinstimmung zweier Rater bei einer beobachtung.

BeispielTabelle hasspostings im Internet:
2 Rater bewerten die selben 20 postings ob sie als hatepost zu klassifizieren sind oder nicht.
```  
|  |  | Rater1 |  |  |
|---|---|---|---|---|
|  |  | shitpost | keinShitpost | gesamt |
| Rater2| shitpost | A:12 | B:2 | 14 |
|  | keinShitpost | C:3 | D:5 | 8 |
|  | gesamt | 15 | 7 | 22 |

k = (pO - probabliltyChance)/(1 - propabilityChance)

p0 = addierte Übereinstimmungen relativ zur gesammtzahl der ratings.
->(A+D)/(A+B+C+D)
->hier also: (12 + 5)/22 = 0.77272 ) -> also alle fälle in denen beide Rater übereinstimmen geteilt durch Gesammtzahl der fälle.

pC -> propabilityChance: zufällig erwarteter Przentsatz der Übereinstimmungen
-> wahrscheinlichkeit das beide rater zufällig übereinstimmen geteilt durch quadrierte gesamtzahl der fälle.
Randsummen gebrochen durch totalsumme aufsummieren.
berechnet nach Formel:
(A+B+C+D = total)
pKorrekt: (A+B)/total * (A+C)/total
pInkorrekt: (C+D)/total * (B+D)/total
pC = pKorrekt + pInkorrekt

hier also:  
koorekt (14/22) * (15/22) = 0.43388
inkorrekt (8/22) * (7/22) = 0.1157  
0.43388 + 0.1157 = 0.54958
bzw. (15x14+7x8)/(22^2) = 0.54958)

Formel:
(pO - pC) / (1 - pC)
(0.77272727272 - 0.54958) / (1 - 0.54958) = 0.4954 -> korrekt.
-> Am ende wird die übereinstimmung der Rater minus die zufällige übereinstimmung der Rater durch die wahrscheinlichkeit geteilt das die Rater absolut übereinstimmen minus die wahrscheinlichkeit das sie zufällig übereinstimmen.

-> "Interrater-Reliablität" >= 0.7 erwünscht -> darunter sollten kriterien zur messung oder beurteilung überarbeitet werden.

-> für metrische Daten eher interklassenkorrelation


### 37. Fragen der Art:

|  |  | BeurteilerIn2 |  | total |
|---|---|---|---|---|
|  |  | Hassposting | Kein Hassposting |
| BeurteilerIn1 | Hassposting | 30 | 5 | 35 |
|  | Kein Hassposting | 15 | 50 | 65 |
| total |  | 45 | 55 | 100

```
pO = (30+50) / 100 = 0,8  
pC = (45x35 + 55x65) / 100^2 = 0.515  
(0,8-0,515)/(1-0,515)  
-> (pO-pC)/(1-pC)  
-> KohensKappa = ca. 0.5876 < 0.7-> nicht gut.
```  

### 38. Schritte beim Zählen von Objekten oder Ereignissen ("was wird gezählt" etc.)

-> Zählen:

```
-> Was wird gezählt?

-> Sind Klassifikationsmerkmale leicht zugänglich?

-> Welche Merkmalsausprägungen der Untersuchungsobjekte werden ausgewählt?

-> Wie sind die einzelnen Kategorien zu gewichten?

-> Qualitative Merkmale quantifizieren:
    - Können zwei(dichotom) oder mehr(polytom) Ausprägungen haben
    - Genauigkeitskriterium: Kategorien müssen exakt definiert sei
    - Exklusivitätkriterium: Kategorien müssen einander wechselseitig ausschließen
    - Exhaustivitäts-Kriterium: Die Kategorien müssen das Merkmal erschöpfend beschreiben (es darf nichts ausgelassen werden)
    - Datenerhebung endet mit der Angabe von Häufigkeiten.

```

### 39. -> Kategorienbildung?

-> Kategorienbildung:

```
-> Hauptarbeit liegt bei der Bildung der Kategorien(vgl. Strukturierende Inhaltsanalyse nach Mayring)

  -> Können a priori aus der Theorie entwickelt (deduktive Kategorienbildung) oder am Material gebildet werden (induktive Kategorienbildung)

    -> Häufig wird eine Mischform verwendet (Hauptkategorien eher deduktiv, Unterkategorien eher induktiv)

  -> Genaue Beschreibung der Haupt und Unterkategorien inklusive Koierregeln und Ankerbeispiele (nicht mehr als 7+-2 Hauptkategorien und nicht mehr als 7+-2 Unterkategorien pro Hauptkategorie)

1. Durchkategorisiern des Materials
2. Mindestens1 unabhängige Raterin erhält Kategorienbescheschreibung und kategorisiert Maerial ebenfalls(ansonsten neues selbst.Rating!)
3. Kappa-Koeffozient > 0.7 sonst überarbeitung des Kategorienschemas samt Beschreibung und
4. neuerlicher Druchlauf.

Indexbildung: aus mehreren variablen wird ein index gebildet.
```


### 40. Ratingskalen

-> Ratingskalen:

```
-> Dabei werden durch Zahlen, verbale Beschreibungen, etc. Abschnitte des Merkmalskontinuums markiert, die der Untersuchungsteilnehmer als gleich groß bewerten soll.
-> Bipolare Ratingskalen:
  Frauen, die bla, halt ich für:
    negativ 1..10 positv
-> Unipolare Ratingskalen:
  Kinder erschweren Gleichbereichtingung
    stimme überhautp nicht zu 1..10 trifft völlig zu
-> Symbolische Marken:
  Häufig bei kindern oder leseschwachen verwendet
  emojis
-> Graphische Ratings: Werden häufig für die Schätzung von Ähnlichkeiten verwendet, bsp burger.
  sehr ähnlich ------ sehr unähnlch
-> Skalenverankerung durch Beispiele(AnchoredScales):
  Hier werden werte durch konkrete Beispiele verankert
```

### 41. Kategorienzahl einer Ratingskala (Auch Osgood.)

-> RatingKategorien:

```  
-> Wieviele Skalenstufen sind optimal?
  - Geradzahlige Stifen erzwingen eine Tendenz(ProblemAuslassung)
  - Ungerazahlige Stufen führen zu einer übermäßigen Tendenz zur Mitte
  - Wählt man skalen mit sehr vielen Stufen(0-100) wählen Befrakten überwiegend stufen, die durch 5 oder 10 teilbar sind.

-> Messtheoretische Probleme:
  - Skalenniveu(ordinal oder intervall=)
  - Decken oder Bodeneffekte
  - Verteulung der untersuchten Objkekte über Merkmalskontinuums
```
-> Osgood:
```
-> Das semantische Differential nach Osgood(1957) später hofstätter(1957,1977)
-> Messung konotativer Bedeutng bzw. affketiver QUalitäten
-> 20-30 7stufige bipolare ratingskalen
-> lassen sich alle auf 3 eigenschaftsdimensionen reduzieren
  - bewertung-evaluation(angenehm vs. unangenehm)
  - macht- potentcy (stark-schwach)
  - Aktivität- activity (erregend- beruigend)
```  

### 42. Was bei schriftlichen Befragungen zu beachten ist.(random-response-technik)

```  
-> Für Befragung homogener Gruppen gedacht.
-> Heterogene Gruppen erfordern eine Segmentierung nach homogenen Gruppen(andere Fragen, texte, help, untersuchungsleriter)
-> Was bezweckt der Fragebogen?
  - ist er ein neues Testinstrument?
  - Soll er Einstellungen messen?
  - Sollen konkrete Verhaltensweisen erfasst werden?
  - Soll eine Bevölkerungsgruppe beschrieben werden?
  - Sollen allgemeine Zustände oder Sachverhalte beschrieben werden?
  - soll etwas evaluert werden?
```
Entwicklungsschritte:

```  
-> 1. Literaturrecherche
  - Caveat: Resultate vergangener Fragebogenanalysen können unkritisch auf eigene Fragestellung übernommen werden.
  - wird fragebogen übersezt muss er neu geeicht werden
  - Fragebogen sollte auf sprachgewohnheiten der zielgruppe ausgerichtet sein.

-> 2. Inhalte
  - liste aller inhalte erstellen, die untersuchungsfokus zuzuordnen sind.
  - !Facettenanalyse: (facetten,des homeoffice die getrennt abgefragt werden könnten)
  Fragestellung wird in grundlegen voneinander unabhängige Elemente untergliedrt, Kombiniert man diese Elemente erhält man fragen die den inhalt vollständig abdecken.

-> 3. Einleitung
  - kurze klare instruktion, anonymität zusichern
  - wer macht die studie?
  - sozialstatistischeFragen an Anfang stellen
  - sprachliche gestaltung auf niveu der befragten

-> 4. Generierung eines Itempools
  - Faustregel: 3x items entwerfen, wie letzlich gebraucht
  - items sind fragen oder statements
  - generell sind fragen mit antwortvorgaben einfacher auszuwerten
  - problem antwortvorgabe, ungradzahlig vs gradzahlig, zu wenige, zu viele antworten
  - antwortkategorien verständlich und vollständig
  - besonderes augenmerk auf starfrage legen, beeinflusst möglicherweise alles
  - keine doppelten verneinungen
  - keine suggestivfragen
  ein item soll nur interessierenden bereich abgrafen

-> 5. Auswahl der Items und Vorversuch
  - Endgültige Fragenauswahl im team kritisch
  - danke an teilnehmer am ende
  - Vorversuch an einem kleinen für die endgültige Stichprobe repräsentativen sample(nmax = 10) mit bitte frage laut auszufüllen.
  - letzteres heißt kognitives testen.

  -> Rücklaufquote: liegt zwisch 10% und 90% -> über 60 ist gut
    - wichtig sind formulierung und layout
    - geringe Rücklaufquote problematisch da samplingbias, systematische verzerrung -> Rücklaufstatistik
```      

-> 6. Vorgabe an eine Population oder Stichprobe(Sampling Strategien)
  -  

### 43. "Gebote nach Porst(2000)"

-> Gebote Porst:

```
1. Du sollst einfache unzeideutige Begriffe verwenden, die von allen Befragten in gleicher Weise verstanden werden!
2. Du sollst lange und komplexe Fragen vermeiden!
3. Du sollst hypothetische Fragen vermeiden!
4. !Du sollst doppelte Stimuli und Verneinungen vermeiden.
5. !Du sollst Unterstellungen und suggestive Fragen vermeiden!
6. Du sollst Fragen vermeiden, die auf Informationen abzielen, über die viele Befragte mutmaßlich nicht verfügen!
7. Du sollst Fragen mit eindeutigen zeitlichem Bezug verwenden.
8. Du sollst Antwortkategorien verwenden, die erschöpfend und disjunkt sind!
9. Du sollst sicherstellen, dass der Kontext einer Frage sich nicht auf deren Beantwortung auswirkt!
10. Du sollst unklare Begriffe definieren.  
```


### 44. Fragen der Art: Sie möchten das Ausmaß an "Ausländerfeindlichkeit" erheben. Skizzieren Sie dazu 1) eine Beobachtung 2) eine Untersuchung mittels Ratingskalen.

### 45. Fragen der Art: Kritisieren Sie (ausfürlich) die folgende Frage eines Erhebungsinstruments: "Ich habe keine Vorurteile oder negative Gedanken gegenüber Menschen aus anderen Kulturkreisen aufgrund von religiösen oder kulturell bedingten Gründen. Stimme zu o Stimme nicht zu o. Skizzieren Sie, wie man es besser machen kann. (Hinweis, mit einer einzigen Frage werden Sie vielleicht nicht ganz auskommen)"

-> 1.6 schriftlichebefragung.

### 46. Testverfälschung
-> Testverfälschung:

```
Test in der Regel nicht belanglos, daher:
  - Siumulation: hohe testwerte werden versucht zu erreichen
  - Dissiumulation: niedrige testwerte werden versucht zu erreichen
  - selbstdarstellung: jeh nach addressat
  - soziale erwünschtheit -> faking good(persöntest)
```  

-> Testverfälschung beheben:
```
  - Ausbalancierte Antworten: alle antworten gleich attraktiv
  - kontrollskalen("lügenskalen"): manchmal benutze ich eine notlüge
  - objektive tests: testziel wird verschleiert
  - aufforderung ordentlich zu arbeiten
```    
- bogus-pipeline:
```  
leuten sagen sie hängen am lügendetector
```
- random-response.Technik,
- unmatched count-technic

### 47. Random-response-Technik

random-response technik:
```  
annahme-> tendez zu verfälschten antworten reduziert sich, wenn die person absolut sicher ist das sich ihr wahres antworten nicht rekonstruieren lässt. würfel sagt ob korrekt oder nicht korrekt antworten.

60% wahrheit, 40% lügen

ja% = 0.5, dann ist 0.6xp + 0.4x1-p die wahrscheinlichkeit in der bevölkerung für pedofinder
0.5= 0.6p + 0.4 - 0.4p
0.1 = 0.2p /0.2
0.5 = p -> beobachtete wahrscheinlichkeit der ja anworten.
```

### 48.Fragen der Art: Ein mittels Random-Response-Technik vorgegebner Fragebogen gibt die Instruktion zur Falschantwort, wenn man in einem Monat von Dezember bis Februar geboren ist. (Annahme: Wahrscheinlichkeit:1/4). Wenn 40% der Befragten eine Frage zustimmend beantworten, für wie groß schätzen Sie den tasächlichen Anteil in der Population? -> gesucht ist 30%.
```  
75% wahr; 25% falsch
p = 0.4

0.4 = 0.75p + 0.25 - 0.25p
0.15 = 0.50p /x2
0.3 = p
```  

### 49. Fragen-der-Art: Ein online-Fragebogen arbeitet mit Random-Response-Technik und der Anleitung: "Antworten Sie wahrheitsgemäß, wenn die (zweistellige) SEkundenangabe Ihrer Uhr, wenn Sie genau jetzt hinsehen, nicht durch 4 teilbar ist, ansonsten genau das GEgentaeil" WEnn Sie auf die Frage nach Missbrauchserfahung nun 35% ja antworten erhalten, was schätuzen sie für den tasächlichen anteil in ihrer stichprobe.
```  
wahr:45s -> 0.75 falsch: 15s-> 0.25 p:0.35

0.35 = 0.75p + 0.25 - 0.25p
0.1 = 0.50p /x2
0.2 = p
tatsächlicher anteil an ja antworten = 20% in der poulation.
```

### 50. Unmatched count-Technik.

- unmatched count:

```
eine gruppe erhält x harmlose items, die andere x harmlose und 1 sensitives. aus differenz lässt sich abschätzen wie viele sensitive "ja" es gab.
```


# Vo.4 Kausalität

### 51. Kausalität, und die Schwierigkeit ihres Nachweises.

-> kausalität

```  
- eigentlich: strenge definition von Ursache, Wirkung und kausalbeziehung.
- bsp waldbrand: wald kann aber auch ohne streichholz, brennen, streichholz o. feuer. oder unsichere handahabung d. feuers,
- kausalbeziehung eigentlich immer kontextabhängig, aber kontextfaktoren oft unbekann.
- wirkung = unterschied zwischen ursache und was gewesen wäre ohne ursache

-> kontrafaktische kausalität bzw rubins kausalmodell:
  wir können nicht beide realitäten(waldbrand feuer ein) zeugen.
-> Strukturgleichungsmodelle setzen zwar kausalität an aber können sie nicht prüfen.
-> granger causality: zeitreihen.wenn xsteigt steigt y

im kern:
-> kontrafakte nicht beobachtbar, mir fehlt die hälfte
-> Experiment muss hinreichend Approximieren, selbe situation und effekt simulieren
-> Natürliches Experiment: Bedingungen sind nicht konrolliert, versuch des vergleichs eines natürlichen erignissen mit vergleichsbedinung.
```  

### 52. Kausalität bei John Stuart Mill

Kausalbedingung existiert wenn:
```  
-> die ursache dem effekt vorangeht
-> die ursache zum effekt in beziehung steht
-> es keine andere plausible erklärung für den effekt gibt als die ursache
```  
mögliche alternativerklärungen können in quasiexperimentellen designs nicht vollständig manupuliert werden.

### 53. Experiment und Feldstudie aus der Sicht der Millschen Kausalität.
```  
Experiment manipulert ursuachen, manche lassen sich jedoch nicht manipulieren (zb geschlecht.)

Experimente sind gut in der kausalbeschreibung aber nicht in der kausalerklärung, die logische beziehung und theorie kann trozdem noch anders sein. _>
kausale erklärungen: helfen aber in der abschätzung der generalisierbarkeit von ergebnissen. welche aspekte der ursache wirken auf welche weise auf aspekte der wirkung => kausalkette.

-> das quasiexperiment kann die ursache nicht randomisieren. ausschließen von alternativerklärungen ist damit quasi unmöglich.
_> alternativerklärungen müsstne vollständig aufgelistet werden.
```  
### 54. Fragen der Art: Zwei zeitlich gleich angesetzte parallele Gruppen einer Lehrveranstaltung haben völlig verschiedene Durchschnittsleistungen auf die Abschlussprüfung. Können Sie das auf die/den LehrveranstaltugsleiterIn zurückführen? Gehen Sie di Millschen Kriterien für Kausallität durch, nd erstellen sie eine Liste an möglichen alternativen Erklärungen. Sind diese alternativen Erklärungen plausibel?

Quasiexperiment:

```  
2 Gruppen, Abschlussprüfung, Ursache:LehrveranstaltungsleiterIn

nein denn:

wenn der lehreranstaltungsleiterIn teilnehmer einer lehrveranstaltng bevorzugt oder anderweitig beeinflusst(quasi als testleitereffekt(halo bzw rosental) bsp einer gruppe immer das gefühl gibt dümmer zu sein)

damit wäre ursache dem effekt voraus
und
die ursache steht zum effekt in beziehung

!allerdings gibt es manifaltige plausible alternativerklärungen für den effekt außer die ursache lehrveranstaltungsleiter.

-> war der lehrveranstaltungsleiter zB der einzige der in beiden klassen gelehrt hat?
-> war das grundniveu der schulklassen das selbe.
```     

### 55. Fragen der Art: In zwei verschiedenen Schulen wird nach zwei verschiedenen Lehrplänen unterrichtet, um festzustellen, welcher besser ist. Um welches Versuchsdesign handelt es sich? Welche alternativen Erklärungen für allfällig beobachtete Effekte kann es geben?

```  
müsste alle möglichen unterschiede der lehrpläne der zwei schulen auflsiten

müssten alle möglichen unterschiede zwischen den schülern und lehrern auflisten

dann entscheiden ob die jeweiligen lehrpläne die unterschiede plausibel erklären können.

sind die leitungsvoraussetzungen der schüler in den zwei bedingungen überhaupt vergleichbar?
```  

### 56. Fassen Sie die wissenschaftskritischen Überlegungen aus der Vorlesungs zusammen und untermauern Sie sie durch zwei selbst gewählte Beispiele.
```  
Wissenschaft folgt manigfaltigen außerwissenschaftlichen prozessen.
-wichtige informationen werden ins persönliche glaubensbild eingebettet.
-schema anwenden und nicht nachdenken:
-kultureller, politischer oder systemischer druck  
-Literaturrecherche wird angepasst das der eigene ansatz damit herauskomme.


-> führt dazu das ratinoale theroiemodifikation im sinne popper nicht stadtfindet.

Beispiel1:

Beispiel2:

```

### 57. Konstruktivismus und seine Abstufungen.

```  
-> Radikalste Form: es gibt überhaupt keine von uns losgelöste Wirklichkeit, alles ist nur ein Konstrukt, eine Vorstellung

-> Weichere From: unsere Vorstellung von der Welt (wissenschaftliche Ergenisse eingeschlossen) ist nur ein Konstrukt, aber es gibt im Prinzip schon so ewas wie eine objektive Welt.


-> Radikale Wissenschaftskritik: wissenschafltiche Beschreibung dieser Welt folgt ausschließlich außerwissenschaftlichen Prozessen, weniger radikale: die Ergebnisse sind von der wirklichen Welt und außerwissenschafltichen prozessen beeinflusst.
```  

### 58. Postnormale Wissenschaft

```  
Funtowics & Ravetz, 1990

- "normal": Wäre wissenschaft liefert wertfreie Fakten, politik entscheidet

- "post-normal": Wissenschaft vertritt selbst werte, die voraussagen sind unsicher und hängen mit der Reaktion von politik und Gesellschaft zusammen, welche anforderungen an die wissenschaft stellt, denn die entschedungen sind dringlich

-> klimawandel, pandemie,
```  

### 59. UTOS-Modell.

```
Kausale !Generalisierbarkeit! bezieht sich auf:

- Units (TeilnehmerInnen)
- Treatments (testmaterial)
- Observations (messungen.)
- Settings, in welchen das Experiment stattfindet.

Konstruktvalidität: Valide Schlussfolgerungen über das Konstrukt, also schließe ich richtig auf glückförderndes Verhalten.

  -> Konstrukt ist meist abstrakter als die Elemente des Experiments
  -> Räpresentieren die elemente wirklich genau die Theorie.

Externe Validität: Generalisierbarkeit über UTOS.
```  

### 60. Fragen der Art: Um den Effekt von home jobbing auf die Arbeitsmotivation (mittels Fragebogen erhoben) festzustellen, werden an einigen Standorten eines Großbetriebs home office-Möglichkeiten geziehlt forciert. Was wäre nach dem UTOS-Modell hinsichtlich der GEneralisierbarkeit der Resultate konkret angewandt auf das Beispiel zu beachten?
Fragebogen: Arbeitsmotivation, homeoffice wird geziehlt forciert(an meheren standorten)
```  
- Units: Die ArbetierInnen bzw. TeilnehmerInnen müssen generalisiert werden, über mehrere standorte ist dies wahrscheinlich gegeben, jedoch muss darauf geachtet werden dass nicht in der einen gruppe nur höhere angestellten homeoffice ermöglicht wird.
- Treatments: hier testmaterial muss generalisert werden, es erhalten also alle teilnehmer die selben fragebögen, auch: gibt es eine generalisierbare kontrollmöglichkeit zum homeoffice?
- Observations: Die fragebögen, die verschiedenen standorte bringen theroretische unterschiede hervor da unterschiedliche testleiter die fragebögen unterschiedlich vorgeben. -> konstruktvalidität muss stimmen.
Settings:  wie unterschiedlich ist die arbeitsmotivation generell an unterschiedlichen standorten? sind diese überhautp annähern mit einander vergleichbar.
```  

### 61. Fragen-der-Art: Worin besteht konkret im vorigen Beispiel 60 externe bzw. interne Validität?

Auf welche Zielpopulation generalisiern wir hier?
```  
- externe Validität: generaliserbarkeit auf arbeitende menschen im großbetrieb allgemein.

- interne validität: arbeiter im genannten großbetrieb.
```

### 62. Ethischen Probleme bei der Durchführung experimenteller Designs.

- Ethische Kodizes (wie z.B. Respekt, Wohlergehen der Teilnehmer*innen, gerechte Aufteilung)
- Informed Consent: Einverständniserklärung der Teilnehmer*innen unter vollständiger Aufklärung über die Bedingungen
- Ethikkommittees (institutional review boards, IRBs)

- nicht behandeln der Kontrollgruppe:
```
-> Dose-response design: medikamente in unterschiedlichen dosen verabreichen
-> teilbehandlung aller personen vor dem versuch
-> Teilweise behandlung on demand
-> wartegruppen, ergro behandlung später-
```
- Randomisierung: abschwächung der randomisierung für dirngede fälle.


# Vo.5 nicht-,Quasie und experimentelle designs.-> wichtig ist experiment oder nicht plus design

### 63. Externe und interne Validität

```  
validität = wahr, gültig
- aussage korrespondiert mit wirklichkeit
- theoriegebäude ist kohärent
- es ist nützlich an eine aussage zu glauben - pragmatismus.
```  

- interne validität- schlüssigkeit des designs, habe ich alle variablen bedacht.
- externe validität- ist das wirklich die theorie und nichts anderes

Bedrohung der Validität:
```  
Validität: wie betrifft die Bedrohung den konkreten Fall?
iSt die bedrohung plausibel oder nur möglich?
wirkt die bedrohung in dieselbe Richtung wie der zu zeigende effekt, könnte ihn also ganz oder teilweise vertäuschen?
```  

### 64. Designs ohne Kontrollgruppe (mit kurzer erklärung)

- Ein-Gruppen-Post-test:

```  
-> nicht-Experimentell , da kontrollgruppe nicht existiert, auch kein quasiexperiment.

-> nur eine gruppe, nach der behandlung getestet.
-> einzellfall sinvoll, effekt einer droge, erinnerung nach film.
-> multiple post-tests können helfen, alternative möglichkeiten auszuschalten(vgl. Feststellung einer Todesursache.)
```  

- Ein-Gruppen-pretest-posttest:

```
voher nacher design
-> nicht Experimentell da kontrollgruppe fehlt.
-> zwei oder mehr zeitpunkte, gemessen voher nachher.

Problematisch ist das alternative erklärungen immer für den effekt bestehen bleiben, zeitliche entwicklung, einfluss der testung selbst

Verbesserungsmöglichkeiten:
-> mehrere Pretests um zeitlichen trend ohne behandlung abzuschätzen
-> hinzufügen nicht äquivalenter abhängiger kontrollvariablen. spielzeug werbung.
```

- Removed treatment:

```  
erst wird behandelt, dann wird diese abgesetzt
aus dem muster der effekte wird alternative erklärung unplausibler.
```  


### 65. Der Ein-Gruppen-Post-Test. Vorteile, Probleme, Aufbesserungsmöglichkeiten. Analog: der Ein-gruppenPrätest-Psttest, der Post-Test mit zwei verschiedenen Gruppen, Versuchplan mit prä-post-test und kontrollgruppe.

- Ein-Gruppen-Post-test:

```  
-> nicht-Experimentell , da kontrollgruppe nicht existiert, auch kein quasiexperiment.

-> nur eine gruppe, nach der behandlung getestet.
-> einzellfall sinvoll, effekt einer droge, erinnerung nach film.
-> multiple post-tests können helfen, alternative möglichkeiten auszuschalten(vgl. Feststellung einer Todesursache.)
```
- Ein-Gruppen-pretest-posttest:

```
voher nacher design
-> nicht Experimentell da kontrollgruppe fehlt.
-> zwei oder mehr zeitpunkte, gemessen voher nachher.

Problematisch ist das alternative erklärungen immer für den effekt bestehen bleiben, zeitliche entwicklung, einfluss der testung selbst

Verbesserungsmöglichkeiten:
-> mehrere Pretests um zeitlichen trend ohne behandlung abzuschätzen
-> hinzufügen nicht äquivalenter abhängiger kontrollvariablen. also droge aufgelöst vs ähnlich schmeckende flüssigkeit
```

- posttest mit zwei verschiedenen Gruppen
```  
-> kein pretest

-> experimentel, aber:
  ->nichtexp wenn keine manipulation
  ->quasiexperiment wenn keine randomisiert

2 gruppen, eine mit eine ohne behandlung.
macht sinn wenn man eine störung durch pretest befürchtet. -> wissenstest

Solomon4groupDesign: mit/ohne vortest kombiniert mit/ohne behandlung

aufbesserung manchmal durch unabhängige pretestgruppe möglich für ver gleich ob post gruppe selben schnitt hat wie ander presonen vor pretest.
```

Allgemeine Verbesserungen:

- multiple kontrollgruppen: mitteln altervantive erklärungen aus
- präzision der hypothesen: wie beim einseitigen testen. je spezifischer die aussage desto einfacher können alternative erklärungen ausgeschlossen werden.

- Versuchsplan mit Prä-Post-Test und Kontrollgruppe:
```  
-> Das Standard Design
-> Mischung aus abhängigem und unahbhängigem Design
(abhängig zwei zweitpuntke, unabhängig zwei gruppen)
-> Experimentell, nicht-exp. oder quasi-exp, jeh nachdem

-> Waurum prä-Test auch in der kontrollgruppe? -> hilft selection bias zu kontrolieren, macht versuchs und kontrollgruppe bez testung identisch, gleiche prätestwerte bedeutet nicht keine prätestunterschiede

-> Effekt von TeilnehmerInnenausfällen besser kontrolierbar
-> Problem: nicht-Additivität was wenn konrtollgruppe auf hüherem level startet? (mehr einkommen)-> nur scheinbar größerer effekt bei kontrolgruoup

Versuchsplanvariante:
- Mehr als ein Pre-tests
- Dritter Zeitpuntk nach Treatment in Kontrollgruppe(TG:1x2+3 vs KG: 1+2x3)
- Reversed Treatment für Kontrollgruppe -> bedingugen sind gegenläufig, sollte effekte verstärken
- Empirische Kontrolle ob Randbedingungen in bedein Gruppen über Zeit gleich.
- kohorten als kontrollgruppe -> ausborgen von kohorte vom jahr davor um kindergartenkinder auf einfluss von sesamstra0e zu vergleichen. -> kontrollgrupe habe ich nur zu einem zeitpunkt
```  


### 66. Formulieren Sie jeweils ein eigenes Beispiel für Ein-Gruppen-Post-Test bzw. Ein-Gruppen-Prätest-posttest und post-Test mit zwei verschiedenen Gruppen, Versuchplan mit Prä-Post-Test und Kontrollgruppe.
```
Beispiele:


```

### 67. Fragen der Art: Angenommen eine Studie möchte feststellen, ob entspannende Musik während des Schlafs aggressive Tendenzen vermindert. Zu diesem Zweck wird 60 Jugendlichen zu Zeitpunkt 1 ein Fragebogen vorgelegt, welcher die Zustimmung zu aggressiven Vorurteilen und aggressiven Bestrafungen von Fehlverhalten misst. Der Fragebogen wird nach 3 Wochen zu Zeitpunkt 2 wiederholt. Dazwischen wird in der Nacht beruhigende Musig aufgelegt, eine Auswahl langsamer Sätze aus Vivaldi-Konzerten. Am Ende werden die Unterschiede in den Fragebogenscores zwischen Zeitpunkt1 und Zeitpunkt2 ausgewertet. Um welches Design handelt es sich? Was sind die Stärken, was die Schwächen dieses Designs? Welche möglichen Alternativerklärungen für allfällige Effekte gibt es, und wie bedrohlich sind sie für die Aussagekradt der Resultate? Welche verbesserungsmöglichkeiten fallen ihnen ein ( denken Sie insbesondere and die in der Vorlesung genannten Punkte)
ein gruppen pretest posttest

### 68. Fragen der Art: Diskutieren Sie die externe Validität der im vorigen Beispiel 67 beschriebenen Studie unter Anwendung des UTOS-Modells.

### 69. Fragen der Art: Sie möchten feststellen, wie stark Jugendliche auf einen Horrorfilm reagieren, die gerade die Altersfreigabe erfüllen. Dazu erheben Sie, wie oft jugendliche Figuren dieses Films in (erinnerte) Trauminhalte der nächsten Woche eingebaut haben. um was für ein design handelt es sich? welche stärken bzw. schwchen weist es auf? gibt es plausible Alternativerklärungen für allfällige Resultate? Wie bedrohlich sind sie für die Interpreation? Inwiefern ändern sich ihre antworten, wenn statt"figuren aus dem Film" nur allgemein "aplträume gezählt werden?"
ein gruppen post test.

### 70. Fragen der Art: Sie erheben den Efekt von Trauma-Therapie anhand von Betroffenen, indem sie das befinden unmittelbar nach dem Trauma bzw. zwei monate später erfassen. um welches design handelt es sich? welche nachteile birgt das design in sich?
- removed treatment oder eingruppenpretestposttest.

### 71. Fragen der Art: Um den Effekt einer neu eingeführten pädagogischen Maßnahme zu prüfen, vergleichen Sie, ob VolksschülerInnen der 2. Klasse dieses Jahr (VOR der Maßnahme) und dann nächstes Jahr (wieder 2. Klasse, NACH Einführung der Maßnahme) besseres Leseverständnis aufweisen (mittels eines standardisierten Tests). Diskutieren Sie (mit entsprechenden Annahmen über die konkrete Situation), inwiefern wegen der fehlenden Randomisierung die Schlüssigkeit der Studie tatsächlich gefährdet ist, und in welchem Ausmaß solche Bedrohungen plausibel angenommen werden können. Gehen Sie dafür mindestens 5 verschiedene mögliche Alternativerklärungen durch. Wie ließe sich das Design schlüssiger machen (insbesondere bezogen auf die von Ihnen angeführten Alternativdeutungen)?

### 72. Fragen der Art: Am Ende eines Deutschkurses für AnfängerInnen testen sie die Deutschkenntnisse der Teilnehmer*innen mittels eines standardisierten Tests, um den Erfolg des Programms zu erheben. Um welches Design handelt es sich, was sind seine Schwächen, und wie könnte man das Design verbessern?

### 73. Fragen der Art: Entwerfen Sie ein Prätest-Posttest-Design mit Versuchs- und Kontrollgruppe für die Fragestellung, ob das Wissen um die Existenz von fake news einer flüchtlingsfeindlichen Einstellung entgegenwirken kann. Bauen Sie passend zur Fragestellung Elemente ein, welche konkurrierende Erklärungen unplausibel machen könnten. Denken Sie etwa an nicht-äquivalente Variablen oder das Vorsehen mehrerer Kontrollgruppen, welche Ihnen spezifischere Vorhersagen erlauben.

### 74. Fragen der Art: Das Umweltministerium und das Bildungsministerium starten gemeinsam eine große Kampagne in daran teilnehmenden österreichischen Schulen, um das Bewusstsein für den Klimawandel zu fördern. Für die Evaluation wird einer repräsentativen Stichprobe vor dem Start und nach Ende der Kampagne ein Fragebogen zum Bewusstsein den Klimawandel betreffend vorgelegt. Zusätzlich wird eine repräsentative Gruppe in nicht teilnehmenden Schulen zu denselben beiden Zeitpunkten getestet Um was für ein Design handelt es sich? Diskutieren Sie Stärken und Schwächen des Designs. Wie ließe es sich aufbessern? Wie könnte man konkurrierende Erklärungen unplausibel machen?

### 75. Fragen der Art: Sie möchten die Ursachen für psychosomatische Beschwerden feststellen und gehen dabei folgendermaßen vor: Über eine Arztpraxis rekrutieren Sie PatientInnen mit psychosomatischen Beschwerden und befragen Sie über deren Lebensbedingungen, und dann vergleichen Sie die Resultate mit einer repräsentativen Stichprobe. Um welches Design handelt es sich? Welche Nachteile hat es? Wie könnte man es aufbessern?

### 76. Schritte, die zu einer schlüssigen Bestätigung einer Theorie aus einer Beobachtung führen könnten. Erklärungen mit eigenem Beispiel.

### 77. Fragen der Art: Eine denkbare Versuchsanordnung zur kognitiven Dissonanz/Rechtfertigung des Aufwands wäre, vor einer Achterbahn Menschen zufällig zu Warteschlangen zuzuteilen und dort verschieden lange warten zu lassen. Wenn jene, welche länger warten mussten, die Fahrt dann auch als aufregender bewerten, würde dann als Bestätigung der Theorie der Rechtfertigung des Aufwands interpretiert. Diskutieren Sie die Schlüssigkeit dieser Vorgehensweise systematisch bzw. erklären Sie, unter welchen Umständen die Schlüssigkeit in höherem/weniger hohem Ausmaß gegeben wäre.

### 78. Signifikanztesten als Elimination alternativer Erklärungen.
```  
-> h0 es gibt keine systematischen Effekte, alternativerklärung für beobachtete effekte (h1)
-> h1 es gibt effekte, die effekte müssen aber nicht zwangsweise mit der theorie in bezug stehen(börsenkurs oder insider)

-> beim signifikanztesten geht es im kern darum eine spezielle alternativerklärung als unplausibel zu bewerten, nämlich den zufall
-> so lange h0 gilt gibt es immer eine alternativerklärung für die effekte, zufall zb.
-> wenn h0 verworfen wird darf ich alternativhypothese annehmen(aber nicht die theorie die dahinter steckt.)
-> wahrscheinlichkeit für ein ergebnis im beobachteten bereich soll so klein sein p<5% dass ich sie nicht mehr als plausible erklärng akzeptiere.
-> statistischen hypothesentesten sollte also so angelegt sein dass es die zufallserklärung unplausibel macht, aber wenn möglich auch alle alternativerklärungen bis auf die eine interessierende.
```
### 79. Fall-Kontrollstudien. Vorteile und Probleme

-> Case controll/fallKontroll:

```  
nicht experimentell, ich kenne ergebnisse und versuche auf ursache zu schließen.

um hypothesen für kausalursachen zu finden.
wie unterscheidet sich vorgeschichte von menschen die zu homeopathie greifen von solchen die es nicht tun.

präzisierung hilft
ethisch oft vorteilhafter als rct, da nicht invasiv

Schwierigkeit:
  - ursachen mit anderen variablen konfundiert.
  - hängt an alter aufzeichung oder erinnerung
  - falsch erinnern kann mit symptom im zusammenhang stehen
  - braucht klarheit was symptome sind
  - diagnosen können sich über zeit verändern
  - vorliegende ursache könnte zu erhhter diagnosewahrscheinlichkeit führen
  - ausfälle bei start der untersuchung
  - publikationbias: verdacht bestätigt eher als gegenteil, wird auch leichter publiziert
  - diagnosewahrscheinlichkeit nicht für jede person/region
  - stichprobengröße wird nicht signifikant.

Hilfe:
  - wahl der Kontrollgrupe: repräsentativ für welche Bevölkerungsgruppe?
  - problem beim parallelisierne: ist merkmal nicht schon symptom? -> gender paygap (auszeiten müssten eigentlich ausparralelisiet werden, können aber natürlich schon symptom der problematik sein)
```

### 80. cross-over-design

```
 2 behandlungen:
 z1 x z2 y z3
 z1 y z2 x z3
 -> um zu verhindern, dass zb ein langzeiteffekt von x mit einem möglichen effekt von y verwechselt wird
```

# Zeitreihendesigns

### 81. Einzelfallanalyse
```  
- Analyse von Einzelfällen hat Tradition in der qualitativen Forschung -> Fallbeschreibung

- In der quantitativen Forschung meint man damit meist die Betrachtung von Zeitreihen

- Schwerpunkt auf individuellen Fallbetrachtungen: „person-centered research“
- Person-oriented research: statistische Auswertung individuell auftretender Merkmalskombinationen („Muster“; Beispiel: Konfigurationsfrequenzanalysen)
  -> was gibt es für individuelle wechselwirkungen.
```  

### 82. Was muss man bei der Auswertung einer zeitlichen Abfolge beachten? Erklärung mit eigenem Beispiel.



```  
beobachtung einer variable über zeit hinweg:
  -> wie verändert intervention verhalten -> einfuhr des allgemeinen tempolimits
  -> mit oder ohne einflussgrößen(schocks) also zeitlicher verlauf an sich oder "folge" von bestimmten einflüssen. reduziert einfuhr eines allgemeinen tempolimits aggressive tendenzen bei autofahrern.

  - werte sind nach treatment größer oder kleiner, der trend verändert sich (schnelleres wachstum), varianzen, zyklische effekte (konjunkturzyklen), autokorrelationen können sich ändern.

Auswertung:
- Effekte können kurzfristig oder langfristig sein
- wirkung kann sofort oder verzögert eintrehten.
- sleeper effect erst nach langer latenzzeit.

!-> art des effekts, dauer sowie verzögerung sind zu berücksichtigen.
!-> die werte sind oft autokorreliert, damit ist statistische auswerung komplozierter -> Arima modelle oder rm anovas.
!-> lange messwertreihen, n>100 -> problem: über zeit einflusseffekte und grunlegende gesetzmäßigkeitenänderung denkbar.

!-> externe einflussgrö0en sind oft relativ unklar bei komplexen sachverhalten.

    Mathematische Verfahren:
      -> Durbin-Watson-Test: auf sequentielle Korreliertheit der Residuen = > Autokorrelationen
      -> Bzw. auf Stationarität testen: Augmented-Dickey-Fuller-Test
      -> ARIMA-Modelle: AR für autoregressives Modell (nächster Wert als lineare Funktion der Vorgänger), I für „integrated“ – ob linear, quadratisch etc., MA for „moving average“ – Reaktion der Zeitreihe auf Fehler bzw. Störungen/Schocks
      -> Bei AR und MA immer die Frage nach der Ordnung: wie viele Zeiteinheiten schauen die Modellgleichungen zurück?
```  

### 83. Das Validitätsproblem, wenn man Effekte auf eine Zeitreihe untersucht, und wie man damit umgeht.

-> generell sehe ich der Zeitreihe nicht an was sonst passiert ist.

-> Zeitliche Einflüsse, Brüche

-> eigentich kann ich nicht einwandfrei alle störvariablen ausschließen (akademisch)

```  
Hauptproblem: „history“, also zeitgleiche Einflüsse anderer Variablen als der zu untersuchende Effekt
Beispiel: politische Interventionen wie etwa Gesetzesänderungen – was passiert noch alles in dieser Zeit?

Brüche in der Zeitreihe: die Erfassung ändert sich, Umstellung der Erhebung, veränderte Definitionen (z.B. Diagnosen), verändertes Bewusstsein
Beispiel: mehr häusliche Gewalt – passiert mehr oder wird nur mehr gemeldet?

Selektion bzw. Population verändert sich

Erweiterungen:
  - Wie schon bei anderen Designs z.B.
  - Non-äquivalente no-treatment group: z.B. Helmpflicht für Kleinmotorräder sollte nur Schäden in dieser Fahrzeugkategorie vermindern, nicht aber für größere Motorräder
  - Non-äquivalente abhängige Variable
  z.B. Öffnungszeiten von Pubs und Alkoholunfälle – stärkster Effekt am Wochenende
  - Externe Validität: funktioniert das auch woanders, in anderem Umfeld?

  -Treatment wieder entfernen
  -Treatment in Vergleichsgruppe zu späterem Zeitpunkt (Bsp: Anstieg der Kriminalität mit Einführung des Fernsehens, in verschiedenen Orten zu verschiedenen Zeiten)
  -Wiederholtes Setzen/Fortnehmen der Behandlung Multiple Pre- und Posttests

Probleme:
  - Treatment oft nicht scharf zu einem Zeitpunkt, stetige Entwicklungen, langsame Verbreitung in Bevölkerung
 - Time delay: verzögerte Wirkung
 - Zeitreihen oft (meist) viel kürzer als 100 Zeitpunkte Weiter zurückliegende Daten nicht immer verfügbar Zeitreihenbrüche
```  

### 84. Was muss man tun, um kausale Effekte innerhalb einer Zeitreihe zu untersuchen? Möglichkeiten, um das zu erreichen

```  
correlation ist nicht causation gilt für zeitreihen besonders.

Bspw. neagtive korrelation uwischen thunfischpopulation und meerestemperatur geht auf überfischung zurück

!alles was zeitlichen trend hat korreliert irgendwie miteinander _> spurious correlations - scheinkorrelation

-> mann muss zeitreihen zunächst stationär machen.
```  

### 85. Stationarität einer Zeitreihe, und warum das wichtig ist

```
- bedeuted trends in zeitreihen herauszurechnen.

- Differenzen bilden wert vom vorwert abziehen.
- Aufendiger aber gründlicher modell in spss schätzen lassen und dann mit den residuen weiterrechnen
- scheinkorrelationen können durch nicht stationärität enstehen

stationarität bedeutet: mittelwer, varianz und autokorrelationen bleiben über die Zeit gleich

autokorrelation: (werte mit sich selbst mit n-1, also vorgänger)
```  

### 86. Fragen der Art: Sie möchten feststellen, ob sich die Wirtschaftskrise auf das Wohlbefinden der Österreicher ausgewirkt hat, indem Sie die zeitliche Entwicklung des BIP mit jener des Wohlbefindens vergleichen. Wie müssen Sie dabei vorgehen?

Zeitreihendesign:

2 zeitachsen, Bip und wohlbefinden.

- stationaritär machen
  -> differenzen bilden
  -> modell rausrechnen.




# Fallzahlenplanung

### 87. Gründe für Fallzahlplanungen

```
- Zu kleine Fallzahlen liefern nicht genug statistische Information, zu große sind unnötig teuer bzw. mit unnötigen Belastungen verbunden (z.B. Nicht- Behandlung in Kontrollgruppen)
- Dementsprechend: vorher zu überlegen!

- In vielen professionellen Untersuchungen Standard, manchmal auch von Gutachter*innen eingefordert
- Letztlich auch eine ethische Forderung...

-> Bei Schätzungen: Schätzfehler soll eine Zielvorgabe nicht übersteigen => Betrachtung des Standardfehlers (absolut oder relativ) bzw. von Konfidenzintervallen

-> Für Hypothesentesten: bestimme Macht soll erreicht werden => Poweranalyse

-> In jedem Fall: Adjustierung nach erwartetem Rücklauf, gegebenenfalls Endlichkeitskorrektur, Berücksichtigung des Designs
```

### 88. Konfidenzintervalle. Wie steigt eine Präzision der Schätzung in Abhängigkeit von der Stichprobengröße?

```  
- Ein Konfidenzintervall enthält den „wahren“ Wert (Populationswert) mit 95%-iger !Sicherheit
Breite des Konfidenzintervalls hängt von n ab:

-> n100= +-10%; n1000= +-3%; n10000= +-1%;

-> Allgemein: um den Fehler auf die Hälfte zu drücken, brauche ich die 4-fache Stichprobengröße (wegen der Wurzel in der Formel)

-> bzw. k2 mal die Stichproben, um Fehler um einen Faktor k kleiner zu machen
```

### 89. Standardfehler



### 90. Fragen der Art: Berechnen Sie ein Konfidenzintervall für den Populationsanteil, wennSie anhand einer Stichprobe von 500 Personen eine Häufigkeit von 30% (also 0.3) beobachten. (gesuchte Zahl: [0.26;0.34])

0.3 = r
500 = n

r +- 1.96 wurzel( r(1-r)/n )

beides positiv!

zwischen dieses beiden punkten sind wir mit 95% !sicherheit.



### 91. Fragen der Art: Eine Umfrage versucht den derzeitigen Wähleranteil einer der österreichischen Parteien zu schätzen. Mit welcher Genauigkeit ist bei n=800 zu rechnen? (Hängt das von der konkreten Partei ab?) (gesuchte Zahl: ± 3.5% bei 95% Sicherheit und 50% beobachtetem Wähleranteil, bei anderen Anteilen noch genauer => 50%-Annahme dient als obere Abschätzung)
???????
n = 800
r = ?




### 92. Schritte bei einer Fallzahlplanung

```
Fallzahlplanung mittels Konfidenzintervallen bzw. wenn Formel für Standardfehler bekannt: wähle n so groß, dass Standardfehler so klein wie gewünscht wird

Die anderen Größen in den Formeln: schätzen, aus Erfahrung oder über den Daumen (z.B. Varianzen), bei Häufigkeiten ist p=0.5 der ungünstigste Fall

Oft richten sich Fallzahlplanungen auf den Nachweis von Effekten relevanter Größe aus, z.B. 2 Punkte auf einer 10-Punkte-visual analog scale, oder es gibt bereits Erfahrungen über die Größe der zu erwartenden Effekte

Als Zielgröße für die Macht wird meist 80% angesetzt. D.h.: wenn die Effektgröße wie vorhergesagt ist, dann beträgt für die errechnete Stichprobengröße die Wahrscheinlichkeit für ein signifikantes Ergebnis 80%. (D.h. 1 Ausgang von 5 wird nicht signifikant!)
```  

### 93. Poweranalyse. Die dabei üblicherweise angestrebte Macht

```
power bzw testmacht hängt ab von der stichprobengröße und größe des effekts(beides muss groß sein)

0.2 klein, 0.5 mittel, 0.8 groß

angestrebt wird üblicherweise ca 0.8 = 0.64 erklärte varianz

software g power
```

### 94. Effektgrößen und ihre Verwendung

- Effektgröße geschätzt aus erfahrung oder festgesetztes kriterium

„Effektgröße“ ist auch ein standardisierter Begriff, Effektgrößen werden verwendet, um Resultate über verschiedene Studien vergleichen zu können (auch wichtig für Metaanalysen)


### 95. Einstufung von Effektgrößen als groß, mittel bzw. klein, und deren Konsequenz für die Fallzahlplanung?

Zum Beispiel für Cohen‘s d standardisierte differenz der gruppenmittelwerte:

-0.2 klein, 0.5 mittel, 0.8 groß
-(pro gruppe) 310=n, 50=n, 20=n,

(0.8 heißt letzlich: 0.8 Standardabweichungen Unterschied)

Pearson Produkt-Moment-Korrelation: r selbst dient als Effektgröße

-0.1 klein, 0.3 mittel, 0.5 groß
-618=n, 68=n, 22=n

(obwohl 0.5 eigentlich nur 25% erklärter Varianz entspricht)

### 96. Die Rolle von Prävalenz und Rücklauf bei einer Fallzahlplanung

-Prävalenz: Prozentsatz der Zielgruppe im sample, z.B. wieviele meiner angeschriebenen Personen haben Kinder oder konsumieren eine bestimmte Produktgruppe
-Rücklauf (completion rate): Prozentsatz innerhalb der angeschriebenen Zielgruppe, welche dann auch wirklich Daten liefern


->!!!Endgültige Stichprobengröße = Anzahl kontaktierter Personen x Prävalenzrate x Rücklaufquote

Stichprobe ist also so zu planen, dass sich je nach erwarteter Prävalenz und Rücklauf am Ende die gewünschte Anzahl von Personen ausgeht, die auch wirklich Daten liefern

Beispiel: n=400 angestrebt, Prävalenz sei 95%, erwarteter Rücklauf 40% => 400/(0.95*0.40) ≈ 1050 Personen zu kontaktieren!

Rücklauf ist unbedingt zu dokumentieren!

### 97. Fragen der Art: Sie schätzen, dass etwa 20% der befragten Mädchen Missbrauchserfahrung aufweisen, und dass nur etwa 10% der Kontaktierten bereit sind, sich von Ihnen befragen zu lassen. Wieviele Personen wären demnach zu kontaktieren, wenn Sie auf eine Stichprobe von 100 auswertbaren Fällen kommen möchten? (gesuchte Zahl: n=5000)

0.2 prävalenzrate
0.1 rücklaufquote
100 angestrebt

100/(0.1x0.2)

### 98. Fragen der Art: Ihr(e) Auftraggeber*in sieht Ihre Fallzahlplanung und meint, dass statt einer Genauigkeit von 5% eine von 1% erreicht werden soll. Was antworten Sie, um wieviel dadurch die Stichprobengröße ansteigen wird? (gesuchte Zahl: Faktor 25, vermutlich nicht machbar)

### 99. Fragen der Art: Es wird ein sehr knappes Ergebnis bei einer Volksabstimmung erwartet. Eine Umfrage mit n=400 Personen prognostiziert eine Zustimmung von 51%. Lässt sich das Ergebnis daraus vorhersagen? Was würden Sie aus dem Stand (ohne Rechnung) vermuten? Was sagt eine genaue Rechnung? ([0.46;0.56])

wurzel 0.51(1-0.51)/400
0.02499499949x1.96 = 0.04899019901
0.04899019901+-0.51=

[0.045;0.56] -> nein


### 100. Fragen der Art: Bei einer postalischen Befragung über Elternschaft rechnen Sie damit, dass 70% der Angeschriebenen tatsächlich Eltern sind, und dass von diesen etwa 20% antworten werden. Wieviele Personen müssen Sie anschreiben, um eine Nettostichprobe von n=500 erwarten zu dürfen? (Ergebnis: 3572)

500/(0.7x0.2)
3571

### 101. Fragen der Art: Sie möchten signifikanzstatistisch untersuchen, ob Psychologiestudierende sich in ihren ethischen Ansichten von Wirtschaftsstudierenden unterscheiden. Was müssten Sie bei einer Fallzahlplanung berücksichtigen? Was für eine Fallzahl könnte Ihrer Einschätzung nach resultieren?



### 102. Fragen der Art: In einer Gemeinderatswahl liegt der Anteil der Wählerschaft einer Bürgermeister-kandidatin bei 52% nach Auszählung von 900 Stimmen. Darf sie schon jubeln? Ändert sich das Resultat, wenn man weiß, dass insgesamt 1000 Stimmen abgegeben wurden? (Unschärfe 3.3% ohne, 1% mit Endlichkeitskorrektur)

### 103. Endlichkeitskorrektur

```  
- Wenn man mit der Stichprobe die Population zu einem merklichen Prozentsatz erfasst, so sinkt dadurch die Messungenauigkeit
(erfasst man die Population, so sinkt der Messfehler auf 0 – Daten vollständig vorhanden)

- Endlichkeitskorrektur = finite population correction (fpc): Messfehlervarianz sinkt um einen Faktor 1-Auswahlsatz, Standardfehler: mit Wurzel dieses Faktors

- Beispiel: 75% der Population erfasst => Standardfehler sinkt um einen Faktor 0.5 (d.h. der nach den üblichen Formeln berechnete Fehler ist mit dieser Korrektur zu multiplizieren)

wurzel 1-wahrscheinlichkeit = standarfehler sinkt um faktor
```  

### 104. Fragen der Art: Wenn Sie von einer Population 50% erhoben haben, um welchen Faktor präzisiert sich dadurch die Messgenauigkeit? (gesuchte Zahl: Standardfehler sinkt um Faktor √(1-0.5)=0.71)

wurzel(1-0.5) = 0.71




### Vo.8 Stichproben


### 105. Gründe für Stichproben anstelle von Vollerhebungen

-> Grundlagen:

```
-Population = Grundgesamtheit (N) = Beobachtungseinheiten, über die eine Aussage getroffen werden soll; oft eine Zielpopulation (target population)
-Vollerhebung: Es werden alle Objekte einer Population untersucht (N).
-Wird nur ein Ausschnitt aus der Population untersucht, spricht man von einer Stichprobe (n)
```

-> warum stichprobe statt vollerhebung:

```
-> Vollerhebung zu aufwändig oder zu viel Belastung
-> Population nicht geschlossen (z.B. Populationen, die ständig wachsen)
-> Population die nur teilweise bekannt (z.B. Population der burnoutgefährdeten Menschen)
-> Population könnte durch Untersuchung gefährdet oder zerstört werden (z,B. Qualitätskontrollen)
```

### 106. Repräsentativität, und wie sie erreicht werden kann

-> Repräsentativität:

```  
-> Repräsentativität -> Stichprobe muss in Zusammensetzung der Population möglichst ähnlich sein

  -> Eine Stichprobe ist (merkmals) spezifisch repräsentativ, wenn ihre Zusammensetzung hinsichtlich relevanter Merkmale der Populationszusammensetzung entspricht.

  -> Eine Stichprobe ist global repräsentativ, wenn ihre Zusammensetzung in nahezu allen Merkmalen der Populationszusammensetzung entspricht.
```  

Wie wird Repräsentativität erreicht:

```  
-> Zufallsstichproben werden mit hinreichender Größe automatisch repräsentativ, sofern der Auswahlrahmen (sampling frame) repräsentativ ist

-> Sonst: sampling frame error (z.B. Telefonbuch, fehlerhafter auswahlrahmen)

-> Problem: Oversampling und Undersampling sowie
Non-Response

-> Dann auch mit wachsender Stichprobe NICHT notwendigerweise repräsentativ!!!
```  

### 107. Arten der Stichprobenziehung (mit jeweils kurzer Erklärung)

Telefonverzeichnisse, Wählerlisten, Zentrales Melderegister (nur amtliche Statistik), Adresslisten, Kundenlisten, Alumni-Listen etc.

Oft keine Zielpopulation vorhanden. oft gibt es geschellschaftliche einflüsse bzw, auch jemand der pfleger ist kann zum beispiel relativ empathielos sein.

Außerdem: Zeitrampen, Verschiebung zwischen Erhebung/targetzeit und Auswahlrahmen.

- Repräsentativität immer in Hinblick auf die Zielpopulation, nicht notwendigerweise Gesamtpopulation


!nur mit probabilistischen stichproben kann man populationsparameter mit entsprechender präzision schätzen.

| propabilistische Stichproben | Nicht-probabilistische Stichproben |
| --- | --- |
| Einfache Zufallsstichprobe  | Ad-hoc-Stichprobe |
| Geschichtete Stichprobe | Theoretische Stichprobe |
| Klumpenstichprobe | Quotenstichprobe |
| Mehrstufige Stichprobe |  |




Nicht-probabilistische Stichproben:
```
  -> Ad-hoc-Stichprobe:


  -> Theoretische Stichprobe:


  -> Quotenstichprobe:
```  

### 108. Mögliche Auswahlrahmen für die Stichprobenziehung

...mit Zufallselement, um systematischen Auswahlfehler zu verhindern

...benötigen Auswahlrahmen, also Liste der statistischen Einheiten

...theoretisch klar überlegen, nachvollziehbar, verhindern bias

• Simple random sampling -> (durch zufall gezogen)
• Systematisches („implizites“) sampling -> ()
• geschichtete Stichprobe (stratified sample)
• Klumpenstrichprobe (Cluster sampling)



### 109. Probabilistische Sampling-Techniken und deren Vorteile/Nachteile (Einfache Zufallstichproben, Systematische Sampling, geschichte Stichproben, Klumpenstichproben)

!nur mit probabilistischen stichproben kann man populationsparameter mit entsprechender präzision schätzen.

## propabilistische Stichproben:


-> Einfache Zufallsstichprobe:

```  
  - simple random sample
  - es wird aus vollständiger Liste aller Objekte der Zielpoulation gezogen
  - Zufallsprinzip -> Alle gleiche Auswahlwarhscheinlichkeit -> n/N(ohne zurücklegen)
  -Problem: jedes Untersuchungsobjekt der population muss erfasst sein.

  - meist mittels zufalsgeneratior oder ähnliches(random-digit dialing)
  - einfach effizient, kein systematischer bias. Konfidenzintervallnach simpler formel, signifikanstest nach simpler formel(t.test,varianzanalyse)
  -> generell: jeh größer n desto repräsentativer das sample


  Implizite Schichtung:
    aus liste jeden kten fall.
    jeder 100ste aus liste, verhinder segmentbildung, außer liste ist schon geordnet.
```

-> Geschichtete Stichprobe:

```   
    - Zielpopulation wird auf Basis bestimmter Merkmale in Teilpoulationen(schichten) eingeteilt (zb geschlecht,alter,ethnie jetzt werden zufälle durch geschlecht unterdrückt)
    - aus jeder Teilpopulation und aus jeder schicht wird zufallsstichprobe entnommen

    - wenn stichprobenumfänge nj zu den teilpopulationen proportional sind spricht man von proportional geschichteten stichproben -> repräsentativ = genau so wie in der population.

    ändert nicht mittelwert.
    aber varianz.



```

-> Klumpenstrichprobe:
  ```
  aus population natürlicher klumpen(schulen, universitäten) werden per zufall anzahl von klumpen gezogen und vollständig untersucht.
  ```

- Mehrstufige Stichprobe
  ```
  klumpen im klumpen wird vollständig untersucht (1stufe,2stufe)
  ```

### 110. Gründe für die Schichtung von Stichproben
```  
Schichtung dann effizient wenn sich die mittelwerte zwischen den schichten stark unterscheiden.

Schichtung 2 anwendungsvorteile:

- sie reduziert die Varianz, die durch die zufälligen Abweichungen von den entsprechenden Eckzahlen entsteht (die Varianz „zwischen“).
- Sie reduziert den systematischen Fehler, der durch mangelnde Repräsentativität hinsichtlich der Schichtungsvariablen entstehen kann (z.B. zu wenig ältere Personen)

Wenn man die Eckzahlen der demographischen Variablen kennt, kann man auch eine sog. Poststratifizierung durchführen, d.h. man wählt die Gewicht der Schichten so, dass sie der Population entsprechen (im nachhinein, d.h. bei der Stichprobenziehung wurde noch nicht geschichtet)
```  

### 111. Fragen der Art: Eine Stichprobe ist geschichtet nach Geschlecht, die 40 Frauen weisen bezüglich der Anzahl der Dienstjahre in der Firma eine Standardabweichung von 3.6 auf, die 20 Männer eine von 4.8. Welche Varianz hat der Mittelwert der Anzahl der Dienstjahre in der Gesamtstichprobe? (gesuchte Zahl: 0.272) Wie lautet der Gesamtmittelwert, wenn die Frauen eine mittlere Anzahl von Dienstjahren 12 und die Männer eine von 9 haben? (Antwort: 11)
Ordentlich:

Formel:
```  
summe (gewichtung * mittelwert) = gesammtmittelwert

summ( gewichtung^2 * ( standardabweichung^2 / n )) = varianz des mittelwertes der Gesamtstichprobe
```  
Rechnung:
```
Standardfehler quadrieren, varianz nicht.

--> (40/60)^2*((3.6^2)/40)
+ (20/60)^2*((4.8^2)/20)

-> unbedingt als ganzes eintippen!

      (40/60)^2= 0.44
      (20/60)^2= 0.11

      (3.6^2)/40 = 0.324
      (4.8^2)/20 = 1.152

      0.44x0.324 + 0.11x1.152

gesammtmittelwert:
  (40/60)x12 + (20/60)x9

```


### 112. Post-Stratifizierung
```  
v 110
Wenn man die Eckzahlen der demographischen Variablen kennt, kann man auch eine sog. Poststratifizierung durchführen, d.h. man wählt die Gewicht der Schichten so, dass sie der Population entsprechen (im nachhinein, d.h. bei der Stichprobenziehung wurde noch nicht geschichtet)

gewichtung wird im nachhinein korriegiert
```  


### 113. Die Größe der Schichten bei einer geschichteten Stichprobe

```  
Oft wählt man die Schichtung proportional, d.h. der Anteil der Schicht in der Stichprobe entspricht genau jenem der Population

Man kann aber auch bewusst over- bzw. undersamplen, z.B. um kleinere Gruppen (z.B. Bundesländer) oder bestimmte Risikogruppen mit ausreichender Stichprobengröße erfassen zu können

Da in die Fehlervarianzen die Varianzen innerhalb der Schichten eingehen, kann man bei optimaler Schichtung die Versuchspersonen so zuteilen, dass mehr Personen jenen Schichten zugeteilt werden, welche sonst besonders viel Fehlervarianz generieren würden

Bei proportionaler Schichtung beträgt die eingesparte Fehlervarianz (Varianz der Schichtmittelwerte)/n (d.h. durch die Schichtung fällt der Fehlerterm „zwischen Schichten“ weg)
```  

### 114. Klumpenstichproben. Eigenschaften, worauf man achten muss

```
-> Klumpenstichprobe oder (Cluster Sample):
  Man zieht aus einer in natürlichen Gruppen (Klumpen) gegliederten Population (z.B. Schulen, Spitäler, Orte etc.) nach dem Zufallsprinzip eine Anzahl von Klumpen und untersucht diese Klumpen dann vollständig.
  • Achtung! die Klumpen dürfen sich nicht überschneiden

-> Die mehrstufige Stichprobe (Multi-Stage Sampling):
  - wenn klumpen aus jeder schule etc nicht ökonomisch sinnvoll.
  Hier wird zunächst zufällig eine Klumpenstichprobe mit großen Klumpen gezogen (1. Stufe); diese Klumpen werden aber nicht vollständig untersucht, sondern aus ihnen wird eine Zufallsstichprobe gezogen (2. Stufe). Daraus kann man wieder eine Klumpenstichprobe gewinnen, aus der man wieder eine Zufallsstichprobe zieht.

Achtung! Der Grund für Klumpenstichproben ist meist technischer oder ökonomischer Natur, hier geht es meist nicht um statistische Vorteile (wie bei der geschichteten Stichprobe)

  -> Im allgemeinen STEIGT der Standardfehler bei Klumpenstichproben im Vergleich zur einfachen Zufallsauswahl

  -> Allerdings bieten Klumpenstichproben interessante analytische Möglichkeiten (Analyse der Varianzen zwischen den Klumpen, Mehrebenenanalysen), um die geht es aber meist nicht
```  


### 115. Unterschiede zwischen Klumpen- und geschichteten Stichproben

```  
Schichten decken – im Gegensatz zu Klumpen – die gesamte Population ab

- (ich wähle nicht zufällig ein paar mögliche Bildungsabschlüsse aus und sample innerhalb von diesen, so wie bei Klumpen...)

- Klumpen bilden meist organisatorische Einheiten ab, Schichten eher demographische Merkmale

- Kleiner Standardfehler bei großen Unterschieden zwischen den Schichten, aber kleinen Unterschieden zwischen den Klumpen
```  

### 116. Erläutern Sie, warum Klumpenstichproben nicht wie einfache Zufallsstichproben ausgewertet werden dürfen.

Zentrales Problem der Klumpenstichproben:

```
- Statistische Einheiten innerhalb der Klumpen i.a. voneinander abhängig

- Hat man jetzt 200 (Schüler*innen) oder 8 (Schulklassen) Einheiten?

- Beispiel: Man beobachtet dass 30 Mädchen geschlechtersepariert unterrichtet „signifikant“ (normaler t-Test) besser in Mathematik sind als 15 Mädchen mit gemischtem Unterricht.

In Wahrheit vergleicht man aber nur eine Klasse mit einer anderen – das KANN nicht signifikant sein!
(Es braucht nur die eine Lehrkraft besser zu unterrichten als die andere, und schon hat man einen scheinbar signifikanten Effekt, weil man de facto ja nicht 45 unabhängige Beobachtungen hat,
  !sondern nur 2)

  fehler zu meinen gunsten.
  wird schnell hoch signifikant.

  mathematische auswertung bei klumpenstichproben deshalb nicht mit standardverfahren möglich -> sodern mehrebenenanlalyse(mixed models zb)
```


### 117. Designeffekt und effektive Stichprobengröße.

```
-> „Designeffekt“: man hat weniger statistische Information zur Verfügung als die Fallzahl vermuten lassen würde
  = weniger statistische Information als bei einfacher Zufallsauswahl

-> Designeffekt = Varianz des Schätzers in komplexer Stichprobe/Varianz bei einfacher Zufallsauswahl

-> „effektive Stichprobengröße“ = tatsächliches n / Designeffekt
  = stichprobengröße als einfache zufallstichprobengröße

-> Abschätzung bei konstanter Clustergröße nc: Designeffekt = 1 + Intraklassenkorrelation x (nc-1)

-> mathematische auswertung bei klumpenstichproben des nicht mit standardverfahren sondern zb mehrebenenanalyse

kaum gruppenunterschiede heißt kaum designeffekt.
```


### 118. Intraklassenkorrelation

```
zwischen 0 und 1

1 heißt: alle varianz nur durch klassenunterschiede (innerhalb: alle werte gleich)
0 heißt keine Klassenunterschiede.

bsp: intercept/(intersecot+resudual)
bzw: varianz "zwischen"/("innerhalb"+"zwischen")

anteil der klassenunterschiede an der totalvarianz

interklassenkorrelation ist hoch wenn es interklassenunterschiede gibt
```  

### 119. Fragen der Art: Berechnen Sie die Intraklassenkorrelation, wenn die Varianz „zwischen“ 1 und die Varianz „innerhalb“ 3 beträgt.

```
varianz "zwischen"/("innerhalb"+"zwischen")
1/(3+1)= 0.25
anteil der klassenunterschiede an der totalvarianz
```  

### 120. Fragen der Art: Berechnen Sie die Intraklassenkorrelation bezüglich Einkommen geclustert nach Firma anhand des folgenden Mehrebenenanalysenoutputs.

|Parameter|Estimate|Std. Error|
|---|---|---|
|Residual|118.330669|17.259689|
|Intercept [subject = Firma]
Variance|77.968608|53.924989|
```
intercept/(intersecot+resudual)
77.968608 / (77.968608+118.330669)
```

### 121. Fragen der Art: Versuchen Sie ein realistisches Beispiel für eine Erhebung mittels Klumpenstichprobe anzugeben, und argumentieren Sie, welchen Designeffekt Sie in etwa erwarten würden. (Hinweis: Sie werden dafür eine Schätzung angeben müssen, wie groß die Intraklassenkorrelation in etwa sein könnte. Die Formel Designeffekt = 1 + Intraklassenkorrelation x (nc-1) müssen Sie – wie alle für den Fragenkatalog benötigten Formeln – für die Prüfung auswendig parat haben.)

```
!!!

kaum gruppenunterschiede heißt kaum designeffekt.
```


### 122. Fragen der Art: Welcher Designeffekt ergibt sich aus einer Intraklassenkorrelation von 0.4 und einer durchschnittlichen Klumpengröße von 20? Was bedeutet dieser Designeffekt? (gesuchte Zahl: 1+0.4*19=8.6)

```  
Designeffekt = 1 + Intraklassenkorrelation x (nc-1)
1 - 0.4 * (20-1) = 8.6

der designeffekt ist eine verzerrung der stichprobe durch die klumpenbildung, eine stichprobe von 860 entspräche einer zufallsichprobengröße von ca 100
bzw. als zufallstichprobengröße ist eine stichprobe in der klumpenstichprobe um den faktor 8.6 veringert.

-> effektive stichprobengröße um 8.6 faches veringert.
```  

### 123. Ad hoc-Stichprobe, theoretische Stichprobe und Quotenstichprobe. Vor- und Nachteile. Unterschied zwischen Quotenstichprobe und geschichteter Stichprobe

-> non-probabelistisches sampling:

```  
- Ad-hoc Stichprobe:
  Gruppe gerade anfallender Personen = schlechteste Möglichkeit; ACHTUNG einen Fragebogen einfach online ins Netz (Facebook) zu stellen entspricht einer Ad-hoc Stichprobe!!!

- Theoretische Stichprobe:
  Wissenschaftler*in sucht nach Vorgabe theoretischer Überlegungen typische oder untypische Fälle bewusst aus.
  -> ExpertinnenSuche, ich helfe selber nach

- Quotenstichprobe:
  Hier werden prozentuale Anteile für bestimmte Merkmalskategorien vorgegeben und eventuell auch für Merkmalskombinationen, die Auswahl innerhalb dieser Quoten bleibt dem Forscher (nicht dem Zufall!) überlassen.

  • ACHTUNG: Dabei resultieren keine repräsentativen Stichproben, da NICHT nach dem Zufallsprinzip gesampelt wird
```

### 124. Fragen der Art: Für eine Einschätzung der Situation der Frau in Österreich möchten Sie drei männliche und drei weibliche ExpertInnen aus der Fakultät ihres Studiums befragen. Chakterisieren Sie die Art der Stichprobe. (Hinweis: Es könnte mehr als ein Begriff anwendbar sein.) Was sind die Nachteile dieses Designs?

```
Theoretische Quotenstichprobe.
jeh nachdem wie expertInnen gewählt auch ad-hoc.

```

# Vo.9 nonresponse

### 125. Möglichkeiten zu Erhöhung Rücklaufquote zu erhöhen. Probleme bei geringem Rücklauf
```
-> Liegen üblicherweise zwischen 10%-90% (>60% ist sehr gut ; je homogener eine Population, desto besser der Rücklauf)
- Postalische Befragungen weisen eher geringe Rücklaufquoten auf, Befragungen die von einer Autorität kommen (z.B. Betriebsrat, Universitäten, Forschungseinrichtungen, etc.) führen zu höheren Rücklaufquoten.


- Kleine ‚Incentives‘ verbessern den Rücklauf! (zu viel bedeutet ich kriege nur leute die es fürs geld machen)
- Interessante Fragestellungen → höhere Rücklaufquote
- Wichtig ist Formulierung der Fragen (Keine Tipp/Rechtschreibfehler!) und Layout.
- Evtl. Erinnerungsschreiben nach Ablauf der Rücksendefrist.
- Eine geringe Rücklaufquote ist dann problematisch, wenn angenommen werden kann, dass sich Personen die antworten von solchen die nicht antworten systematisch unterscheiden

Non-Responder-Analyse: Wenn bestimmte (basis-) soziodemographische Daten der Stichprobe bekannt sind, dann grundsätzlich die Responder mit den Non-Respondern auf statistische Unterschiede hin abtesten. In großen Befragungen kann und wird dann entsprechend nachgewichtet. Um Ergebnisverzerrungen zu verhindern

-> ist der Rücklauf zu gering kann ich wahrscheinlich davon ausgehen das die daten an sich schon verzerrt sind da hier ein auswahlprozess stadfindet. es könnte ein systematischer Fehler sein.
```  


### 126. Arten von non-response

```
-> Unit non-response: statistische Einheit (Person, Unternehmen...) gibt überhaupt keine Antworten (bzw. nimmt an Untersuchung nicht teil

-> Item non-response: einzelne Antworten fehlen = Items wurden nicht beantwortet; „missing values“
```

### 127. Probleme durch fehlende Werte

```
Probleme durch non-response:

- weniger statistische Information (Verlust an Stichprobengröße) = unsystematischer Fehler

- Non-response bias
  Ergebnisse sind systematisch verzerrt, weil sich die Personen mit fehlenden Antworten systematisch von denen unterscheiden, die geantwortet haben

Das bezieht sich sowohl auf unit- als auch auf item non-response
```

### 128. Ursachen für unit non-response

-> Unit non-response:

```
Non-Respondent*innen...
• haben kein Vertrauen (z.B. Datenschutz)
• Sind nicht interessiert („Zeitverschwendung“)
• lehnen die Fragen oder die Erhebung ab
• haben keine Zeit
• senden nicht zurück oder scheitern daran
• sind verhindert (krank, auf Ferien, nicht im Lande)
...etc.
```

### 129. Ursachen für item non-response

-> Item non-response:

```  
Non-Respondent*innen...
• übersehen eine Frage oder vergessen darauf
• sind nicht oder nicht mehr interessiert
• lehnen die Frage ab oder sind verärgert
• wollen die Information nicht preisgeben (sensitive Information)
• schämen sich zu antworten
• kennen die Antwort nicht
• verstehen die Frage nicht
• haben keine passenden Antwort
(Fleischpräferenzen bei Vegetarier*innen, weder „männlich“ noch „weiblich“)
• haben nur eine sehr komplizierte Antwort
• ...etc.

Datenschutzgesetz in Österreich: alle auf individuelle Personen bezogenen Daten sind prinzipiell vertraulich,
„sensible Daten“ (besonders geschützt): „Daten natürlicher Personen über ihre rassische und ethnische Herkunft, politische Meinung, Gewerkschafts- zugehörigkeit, religiöse oder philosophische Überzeugung, Gesundheit oder ihr Sexualleben“
```  

### 130. Beispiele für non-response bias.

Beispiele:

```  
- Haushalte mit sehr hohen oder niedrigen Einkommen weniger zur Teilnahme an Erhebungen bereit
Folge: extreme Haushalte unterrepräsentiert, beispielsweise könnte at-risk-of-poverty rate (Armutsgefährdungsquote) unterschätzt werden

- Traditionelle Männer könnten bei Befragung über  Genderrollen teilnehmen wollen
Folge: Traditionalismen in den Resultaten zu wenig sichtbar

- Online-Fragebögen: u.a., ältere Personen unterrepräsentiert => Gesundheit? Wahlverhalten?
```

MCAR, MAR, notMissingAtRandom:

```
-> Missing completely at random (MCAR): Ausfall unabhängig von der Ausprägung des erfragten Merkmals oder anderer Merkmale der Person

  -> MCAR => kein bias durch non-response, nur unsystematischer Fehler


-> Missing at random (MAR): Ausfall unabhängig von der Ausprägung des erfragten Merkmals, ABER abhängig von der Ausprägung anderer bekannter Merkmale der Person

  -> MAR => kein Bias wenn die entsprechenden (meist demographischen) Variablen kontrolliert werden
  Ausfall abhängig von unbekannten Variablen: bias schwer abzuschätzen, wenn Stichprobe nicht repräsentativ bzgl. der unbekannten Einflussgröße


-> Ausfall unabhängig von der Ausprägung des erfragten Merkmals, aber auch abhängig von unbekannten Merkmalen (oft nicht gesondert angeführt)


!!!-> Not missing at random: Ausfall direkt abhängig vom Wert der erfragten Variablen

  -> Not missing at random: schlimmster bias, systematische Verzerrung der vorhandenen Antworten, kaum kontrollierbar (am besten: non-responder analysis, siehe später)
```  

### 131. Möglichkeiten, mit non-response umzugehen, und deren Nachteile.

- vermeiden,
- ignorieren, MCAR
- gewichten = post-stratifizieren -> MAR
- imputieren -> mar (funktioniert nicht für notmar)

```
- Vermeiden wo möglich (Freundlichkeit, schriftliche Ankündigungen, sorgfältige Fragenformulierungen, wiederholte Kontaktversuche, reminders, Erinnerungsschreiben, incentives = kleine Entschädigungen)
  -> Vorbeugen ist besser als heilen, beste

- Ignorieren des Problems: SPSS default! Reduktion auf vollständige Fälle in den beteiligten Variablen. Bias möglich.

- Aufgewichten unterrepräsentierter Gruppen (beiunit non-response); z.B. 30 % Personen 60+ anstatt der angezielten 40 % durch non-respose => Gewicht 40/30 (andere Gruppen analog). Für MAR. p-Werte dann über complex samples o.ä. berechnen!

- Imputation (für item non-response): ersetze fehlende Werte durch plausible. Problem: erfundene Daten

- Abwägung: mit verzerrten Daten leben vs. mit erfundenen Daten leben
```

### 132. Imputation und Imputationstechniken

```
- Deductive imputation: Wert kann logisch „verlässlich“ erschlossen werden (80+ => Pension; fehlende Reisekosten selber schätzen)

- Imputation des Gruppenmittelwerts (verändert Verteilung, wird schlanker! Noch zufälligen Fehlerterm einfügen)

- Imputation eines Zufallswerts oder einer bestimmten Verteilung entsprechend (Gefahr der „Verwässerung“ der Verteilung bzw. der Zusammenhänge)

- Spendermodelle: Ersetzung durch Wert von ähnlicher Person („hot deck“ = Werteliste von Personen mit gleichen Charakteristiken, wähle sukzessiv von dort; „nearest neighbour“)

- Regressionsmodelle: sage fehlenden Werte aufgrund anderer Merkmale vorher (um Varianz zu erhalten, werden wieder zufällige Fehlerterme eingeführt)
```

### 133. Little’s MCAR-Test

```
- Little‘s MCAR test testet, ob Werte MCAR sind

- Hier: signifikant, das bedeutet, NICHT MCAR, fehlende Werte sollten NICHT einfach ignoriert werden

- Unter „EM“ oder „Regression“ können die imputierten Werte auch gespeichert werden
```

### 134. Multiple Imputation

```
- Erzeugt mehrere Versionen des Datensatzes mit jeweils verschieden imputierten fehlenden Werten

- in PISA, PIAAC etc. „plausible values“

- Korrekte Auswertung : gewünschte Auswertung (Mittelwert, Korrelation, was auch immer) mit jedem der erzeugten Datensätze extra rechnen, am Ende bekommt man eine Ziehung aus der (a posteriori-) Verteilung der gesuchten Kenngröße => Fokus liegt mehr in der erzielten Verteilung als auf einer Punktschätzung
```

### 135. Probleme bei der Imputation von Daten

```  
- Fiktive Daten!!!

- Korrektep-values schwierig (weniger unabhängige statistische Information in den Daten als Computer glaubt)

- Univariate Verteilungen normalerweise gut angenähert

- Bivariate Verteilungen können unbrauchbar sein, wenn Variablen unabhängig voneinander komplettiert wurden

- Beispiel: Geschlecht imputiert nach Region, Bildung, Familienstand => bei Verkreuzung mit Beruf katholische Priesterinnen möglich, bzw. zu viele Kindergärtner, Fußballtrainerinnen oder Männer in Karenz

- Offensichtlich falsche oder unplausible Werte generieren ähnliche Probleme wie fehlender Werte
(Beispiel: Angabe eines Schüler*innenwohnorts: Schlumpfhausen)
```  

### 136. data editing

```
- Datenbereinigung bzw. „Korrektur“

- => Wichtigkeit von Plausibilitätschecks, „data editing“ und „data cleaning“, viel Aufwand in nationalen Erhebungen!

- Teils händisch, teils maschinell

- Auf Mikroebene = Stimmigkeit innerhalb einer Person und auf Makroebene = Plausibilität der globalen Verteilung (z.B.: kann es so viele oder so wenige Schulabbrecher*innen geben?)

- Beispiel: Angaben von Löhnen unter Kollektivvertrag => möglich oder nicht?
```  

### 137. Fragen der Art: Sie lesen eine Auswertung, in welcher über den Umgang mit fehlenden Werten nicht berichtet wird. Welche Fragen stellen sich? (Hinweis: ob es fehlende Werte gab, was wahrscheinlich ist, und welche Arten von Verzerrung dementsprechend stattgefunden haben könnten bzw. in welchem Ausmaß.)

### 138. Fragen der Art: Erfahrungsgemäß kann es vorkommen, dass Wähler*innen einer bestimmten Partei in Wahlumfragen nicht angeben, diese wählen zu wollen. Um welche Art von non-response handelt es sich dabei, und was ist dementsprechend zu befürchten?

### 139. Fragen der Art: Angenommen Männer wären weniger dazu bereit, in einem Fragebogen eine Frage zur Qualität ihrer Beziehung zu beantworten. Um welche Art von non-response handelt es sich dabei, welche Auswirkung könnte er haben, und was lässt sich dagegen tun?

### 140. Fragen der Art: Angenommen Sie stellen fest, dass bei einer Mitarbeiter*innenbefragung bevorzugt die sehr zufriedenen und die sehr unzufriedenen teilnehmen sowie jene, die noch nicht lange im Betrieb sind (die Dauer der Betriebszugehörigkeit wird erfragt). Um welche Arten von non-response handelt es sich dabei, welche Auswirkung könnten sie haben, und was lässt sich dagegen tun?

### 141. Non-responder-Analyse und ihr Einsatz

Non-responder analysis:

= Analyse ob Antwortausfälle sich bei Fällen mit bestimmten Charakteristiken häufen

• im Datensatz selbst

• oder über erneuten Kontakt zu Non-
Responder*innen mit reduziertem Fragenset (würden sie uns antworten wenn wir sie anrufen?)

• ... einige werden wenigstens jetzt antworten

• Die Merkmale hartnäckig Verweigernder bleiben aber nach wie vor im Dunkeln

### 142. Propensity score matching und dessen Einsatz

Propensity score matching:
```
- Rosenbaum & Rubin, 1983

- Wie wahrscheinlich ist es das eine person mit diesen merkmalen ausfällt.
-> am ende kann ich aus bekannten effekten bestimmte gruppenwerte schließe

- Propensity score = schätze die Wahrscheinlichkeit, Treatment- bzw. Kontrollgruppe anzugehören, aus diversen Kovariaten (wie in logistischer Regression); habe damit gleichsam die prä- experimentellen Unterschiede bzw. die Verzerrung bei der Zuordnung zu den Gruppen modelliert

- Z.B. könnte es wahrscheinlicher sein, als Frau in die Stichprobe zu kommen

- Kovariaten: meist demographische Variablen
propensity scores reduzieren die diversen möglichen Verzerrungen auf eine Dimension: gewisse Merkmale sind wahrscheinlicher in der Stichprobe als andere

- = verwende den propensity score, um parallele Stichproben zu generieren

- Z.B. nearest neighbour: ordne einer Person in der Versuchsgruppe einer in der Kontrollgruppe zu, welche einen möglichst ähnlichen propensity score aufweist

- Problem: finde vielleicht keine geeigneten Paare

- Abhängig von der Wahl der Kovariaten

- Sollte mit einer Sensitivitätsanalyse verbunden werden = führe das matching auf verschiedene Arten durch (insbes. mit verschiedenen Auswahlen der Kovariaten) und prüfe, ob das Ergebnis stabil ist oder sich je nach Methode verändert
```

### 143. Propensity score matching und das Problem fehlender Werte

```
- Berechne propensity scores als Wahrscheinlichkeit, eine fehlende Antwort zu generieren (wieder mit diversen Kovariaten als Prädiktoren)

- Kategorisiere den score, z.B. in 5 Klassen

- Basiere die Auswertung auf einer Stichprobe, welche nach diesen Klassen geschichtet ist (bzw. post-stratifiziert)

- Sollte Verzerrungen reduzieren, die durch systematische Zusammenhänge zwischen non- response und Kovariaten entstehen

- Bzw. propensity score matching: suche Fall mit ähnlichem propensity score, nehme den Wert von dort
```
